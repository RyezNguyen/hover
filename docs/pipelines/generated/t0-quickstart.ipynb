{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ecc29bb",
   "metadata": {},
   "source": [
    "> Welcome to the basic use case of `hover`!\n",
    ">\n",
    "> :sunglasses: Let's say we want to label some data and call it a day.\n",
    "\n",
    "-   <details open><summary>Dependencies for {== local environments ==}</summary>\n",
    "    When you run the code locally, you may need to install additional packages.\n",
    "\n",
    "    To run the text embedding code on this page, you need:\n",
    "```shell\n",
    "    pip install spacy\n",
    "    python -m spacy download en_core_web_md\n",
    "```\n",
    "\n",
    "    To render `bokeh` plots in Jupyter, you need:\n",
    "```shell\n",
    "    pip install jupyter_bokeh\n",
    "```\n",
    "\n",
    "    If you are using JupyterLab older than 3.0, use this instead ([reference](https://pypi.org/project/jupyter-bokeh/)):\n",
    "```shell\n",
    "    jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "    jupyter labextension install @bokeh/jupyter_bokeh\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "## **Ingredient 1 / 3: Raw Data**\n",
    "\n",
    "Start with a spreadsheet loaded in `pandas`.\n",
    "\n",
    "We turn it into a [`SupervisableDataset`](../../reference/core-dataset/#hover.core.dataset.SupervisableDataset) designed for labeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5445778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T01:59:22.888656Z",
     "iopub.status.busy": "2023-06-06T01:59:22.888172Z",
     "iopub.status.idle": "2023-06-06T01:59:24.244692Z",
     "shell.execute_reply": "2023-06-06T01:59:24.244037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: Initializing</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: Initializing\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: Deduplicating</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: Deduplicating\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: --subset raw rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">974</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: --subset raw rows: \u001b[0m\u001b[1;36m1000\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m974\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: --subset train rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: --subset train rows: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: --subset dev rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: --subset dev rows: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: --subset test rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: --subset test rows: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">游릭 SupervisableTextDataset: Set up label encoder/decoder with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008000; text-decoration-color: #008000\"> classes.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m游릭 SupervisableTextDataset: Set up label encoder/decoder with \u001b[0m\u001b[1;36m0\u001b[0m\u001b[32m classes.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">游릭 SupervisableTextDataset: Population updater: latest population with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008000; text-decoration-color: #008000\"> classes.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m游릭 SupervisableTextDataset: Population updater: latest population with \u001b[0m\u001b[1;36m0\u001b[0m\u001b[32m classes.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: finished setting up bokeh elements.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: finished setting up bokeh elements.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">游릭 SupervisableTextDataset: finished initialization.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m游릭 SupervisableTextDataset: finished initialization.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>SUBSET</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, it's been a while since this was discu...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>About 25 is correct for Numminen and Lumme. ...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am in the market for a 24-bit graphics card...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I hope you realize that for a cellular phone,...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes.   Please describe these \"number of ways\"...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text SUBSET    label\n",
       "0    Well, it's been a while since this was discu...    raw  ABSTAIN\n",
       "1    About 25 is correct for Numminen and Lumme. ...    raw  ABSTAIN\n",
       "2   I am in the market for a 24-bit graphics card...    raw  ABSTAIN\n",
       "3   I hope you realize that for a cellular phone,...    raw  ABSTAIN\n",
       "4   Yes.   Please describe these \"number of ways\"...    raw  ABSTAIN"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hover.core.dataset import SupervisableTextDataset\n",
    "import pandas as pd\n",
    "\n",
    "example_csv_path = \"https://raw.githubusercontent.com/phurwicz/hover-gallery/main/0.5.0/20_newsgroups_raw.csv\"\n",
    "# for fast, low-memory demonstration purpose, sample the data\n",
    "df_raw = pd.read_csv(example_csv_path).sample(1000)\n",
    "df_raw[\"text\"] = df_raw[\"text\"].astype(str)\n",
    "\n",
    "# data is divided into 4 subsets: \"raw\" / \"train\" / \"dev\" / \"test\"\n",
    "# this example assumes no labeled data available., i.e. only \"raw\"\n",
    "df_raw[\"SUBSET\"] = \"raw\"\n",
    "\n",
    "# this class stores the dataset throught the labeling process\n",
    "dataset = SupervisableTextDataset.from_pandas(df_raw, feature_key=\"text\", label_key=\"label\")\n",
    "\n",
    "# each subset can be accessed as its own DataFrame\n",
    "dataset.dfs[\"raw\"]().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2ddccb",
   "metadata": {},
   "source": [
    "-   <details open><summary>FAQ</summary>\n",
    "    <details open><summary>What if I have multiple features?</summary>\n",
    "        `feature_key` refers to the field that will be vectorized later on, which can be a JSON that encloses multiple features.\n",
    "\n",
    "        For example, suppose our data entries look like this:\n",
    "```python\n",
    "        {\"f1\": \"foo\", \"f2\": \"bar\", \"non_feature\": \"abc\"}\n",
    "```\n",
    "\n",
    "        We can put `f1` and `f2` in a JSON and convert the entries like this:\n",
    "```python\n",
    "        # could also keep f1 and f2 around\n",
    "        {'feature': '{\"f1\": \"foo\", \"f2\": \"bar\"}', 'non_feature': 'abc'}\n",
    "```\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Can I use audio or image data?</summary>\n",
    "        Yes! Please check out the \"Guides\" section of the documentation.\n",
    "    </details>\n",
    "\n",
    "</details>\n",
    "\n",
    "## **Ingredient 2 / 3: Embedding**\n",
    "\n",
    "A pre-trained embedding lets us group data points semantically.\n",
    "\n",
    "In particular, let's define a `data -> embedding vector` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c881ce09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T01:59:24.248310Z",
     "iopub.status.busy": "2023-06-06T01:59:24.247823Z",
     "iopub.status.idle": "2023-06-06T01:59:27.775919Z",
     "shell.execute_reply": "2023-06-06T01:59:27.775052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:   Well, it's been a while since this was discussed so i take the liberty of reprinting (without permission, so sue me) Eric Haines reprint of the very interesting discussion of this topic...                  /Jonas                           O /         \\ O ------------------------- X snip snip X ------------------------------                          O \\         / O  \"Give a man a fish, and he'll eat one day. Give a man a fishing rod, and he'll laze around fishing and never do anything.\"  With that in mind, I reprint (without permission, so sue me) relevant information posted some years ago on this very problem.  Note the early use of PostScript technology, predating many of this year's papers listed in the April 1st SIGGRAPH Program Announcement posted here a few days ago.  -- Eric   Intersection Between a Line and a Polygon (UNDECIDABLE??),  by Dave Baraff, Tom Duff   From: deb@charisma.graphics.cornell.edu  Newsgroups: comp.graphics  Keywords: P, NP, Jordan curve separation, Ursyhon Metrization Theorem  Organization: Program of Computer Graphics   I think that this is a very difficult problem.  To start with, lines and polygons are semi-algebraic sets which both contain uncountable number of points.  Here are a few off-the-cuff ideas.  First, we need to check if the line and the polygon are separated.  Now, the Jordan curve separation theorem says that the polygon divides the plane into exactly two open (and thus non-compact) regions.  Thus, the line lies completely inside the polygon, the line lies completely outside the polygon, or possibly (but this will rarely happen) the line intersects the polyon.  Now, the phrasing of this question says \"if a line intersects a polygon\", so this is a decision problem.  One possibility (the decision model approach) is to reduce the question to some other (well known) problem Q, and then try to solve Q.  An answer to Q gives an answer to the original decision problem.  In recent years, many geometric problems have been successfully modeled in a new language called PostScript.  (See \"PostScript Language\", by Adobe Systems Incorporated, ISBN # 0-201-10179-3, co. 1985).  So, given a line L and a polygon P, we can write a PostScript program that draws the line L and the polygon P, and then \"outputs\" the answer.  By \"output\", we mean the program executes a command called \"showpage\", which actually prints a page of paper containing the line and the polygon.  A quick examination of the paper provides an answer to the reduced problem Q, and thus the original problem.  There are two small problems with this approach.    (1) There is an infinite number of ways to encode L and P into the  reduced problem Q.  So, we will be forced to invoke the Axiom of  Choice (or equivalently, Zorn's Lemma).  But the use of the Axiom of  Choice is not regarded in a very serious light these days.   (2) More importantly, the question arises as to whether or not the  PostScript program Q will actually output a piece of paper; or in  other words, will it halt?   Now, PostScript is expressive enough to encode everything that a  Turing Machine might do; thus the halting problem (for PostScript) is  undecidable.  It is quite possible that the original problem will turn  out to be undecidable.   I won't even begin to go into other difficulties, such as aliasing, finite precision and running out of ink, paper or both.  A couple of references might be:  1. Principia Mathematica.  Newton, I.  Cambridge University Press, Cambridge,    England.  (Sorry, I don't have an ISBN# for this).  2. An Introduction to Automata Theory, Languages, and Computation.  Hopcroft, J    and Ulman, J.  3. The C Programming Language. Kernighan, B and Ritchie, D.  4. A Tale of Two Cities. Dickens, C.  --------  From: td@alice.UUCP (Tom Duff) Summary: Overkill. Organization: AT&T Bell Laboratories, Murray Hill NJ  The situation is not nearly as bleak as Baraff suggests (he should know better, he's hung around The Labs for long enough).  By the well known Dobbin-Dullman reduction (see J. Dullman & D. Dobbin, J. Comp. Obfusc. 37,ii:  pp. 33-947, lemma 17(a)) line-polygon intersection can be reduced to Hamiltonian Circuit, without(!) the use of Grobner bases, so LPI (to coin an acronym) is probably only NP-complete.  Besides, Turing-completeness will no longer be a problem once our Cray-3 is delivered, since it will be able to complete an infinite loop in 4 milliseconds (with scatter-gather.)  --------  From: deb@svax.cs.cornell.edu (David Baraff)  Well, sure its no worse than NP-complete, but that's ONLY if you restrict yourself to the case where the line satisfies a Lipschitz condition on its second derivative.  (I think there's an '89 SIGGRAPH paper from Caltech that deals with this).  --\n",
      "Vector shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "from functools import lru_cache\n",
    "\n",
    "# use your preferred embedding for the task\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# raw data (str in this case) -> np.array\n",
    "@lru_cache(maxsize=int(1e+4))\n",
    "def vectorizer(text):\n",
    "    clean_text = re.sub(r\"[\\s]+\", r\" \", str(text))\n",
    "    return nlp(clean_text, disable=nlp.pipe_names).vector\n",
    "\n",
    "text = dataset.dfs[\"raw\"]().loc[0, \"text\"]\n",
    "vec = vectorizer(text)\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Vector shape: {vec.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d834b49",
   "metadata": {},
   "source": [
    "-   <details open><summary>Tips</summary>\n",
    "    <details open><summary>Caching</summary>\n",
    "        `dataset` by itself stores the original features but not the corresponding vectors.\n",
    "\n",
    "        To avoid vectorizing the same feature again and again, we could simply do:\n",
    "```python\n",
    "        from functools import cache\n",
    "\n",
    "        @cache\n",
    "        def vectorizer(feature):\n",
    "            # put code here\n",
    "```\n",
    "\n",
    "        If you'd like to limit the size of the cache, something like `@lru_cache(maxsize=10000)` could help.\n",
    "\n",
    "        Check out [functools](https://docs.python.org/3/library/functools.html) for more options.\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Vectorizing multiple features</summary>\n",
    "        Suppose we have multiple features enclosed in a JSON:\n",
    "```python\n",
    "        # could also keep f1 and f2 around\n",
    "        {'feature': '{\"f1\": \"foo\", \"f2\": \"bar\"}', 'non_feature': 'abc'}\n",
    "```\n",
    "\n",
    "        Also, suppose we have individual vectorizers likes this:\n",
    "```python\n",
    "        def vectorizer_1(feature_1):\n",
    "            # put code here\n",
    "\n",
    "        def vectorizer_2(feature_2):\n",
    "            # put code here\n",
    "```\n",
    "\n",
    "        Then we can define a composite vectorizer:\n",
    "```python\n",
    "        import json\n",
    "        import numpy as np\n",
    "\n",
    "        def vectorizer(feature_json):\n",
    "            data_dict = json.loads(feature_json)\n",
    "            vectors = []\n",
    "            for field, func in [\n",
    "                (\"f1\", vectorizer_1),\n",
    "                (\"f2\", vectorizer_2),\n",
    "            ]:\n",
    "                vectors.append(func(data_dict[field]))\n",
    "\n",
    "            return np.concatenate(vectors)\n",
    "```\n",
    "    </details>\n",
    "\n",
    "</details>\n",
    "\n",
    "## **Ingredient 3 / 3: 2D Embedding**\n",
    "\n",
    "We compute a 2D version of the pre-trained embedding to visualize the whole dataset.\n",
    "\n",
    "Hover has built-in methods for calling [umap](https://umap-learn.readthedocs.io/en/latest/) or [ivis](https://bering-ivis.readthedocs.io/en/latest/).\n",
    "\n",
    "-   <details open><summary>Dependencies (when in your own environment)</summary>\n",
    "    The libraries for this step are not directly required by `hover`:\n",
    "\n",
    "    -   for umap: `pip install umap-learn`\n",
    "    -   for ivis: `pip install ivis[cpu]` or `pip install ivis[gpu]`\n",
    "\n",
    "    `umap-learn` is installed in this demo environment.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19dff92c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T01:59:27.780108Z",
     "iopub.status.busy": "2023-06-06T01:59:27.779731Z",
     "iopub.status.idle": "2023-06-06T01:59:51.983290Z",
     "shell.execute_reply": "2023-06-06T01:59:51.982458Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 974/974 [00:02<00:00, 338.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: Fit-transforming UMAP on </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">974</span><span style=\"color: #000080; text-decoration-color: #000080\"> samples</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: Fit-transforming UMAP on \u001b[0m\u001b[1;36m974\u001b[0m\u001b[34m samples\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/work/hover/hover/.tox/test_notebook_generation/lib/python3.9/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/runner/work/hover/hover/.tox/test_notebook_generation/lib/python3.9/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/runner/work/hover/hover/.tox/test_notebook_generation/lib/python3.9/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/runner/work/hover/hover/.tox/test_notebook_generation/lib/python3.9/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: Transforming UMAP on </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> samples</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: Transforming UMAP on \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m samples\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">游릭 SupervisableTextDataset: Computed </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #008000; text-decoration-color: #008000\">-d embedding in columns </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'embed_2d_0'</span><span style=\"color: #008000; text-decoration-color: #008000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'embed_2d_1'</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m游릭 SupervisableTextDataset: Computed \u001b[0m\u001b[1;36m2\u001b[0m\u001b[32m-d embedding in columns \u001b[0m\u001b[1;32m[\u001b[0m\u001b[32m'embed_2d_0'\u001b[0m\u001b[32m, \u001b[0m\u001b[32m'embed_2d_1'\u001b[0m\u001b[1;32m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>SUBSET</th>\n",
       "      <th>label</th>\n",
       "      <th>embed_2d_0</th>\n",
       "      <th>embed_2d_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, it's been a while since this was discu...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>8.699749</td>\n",
       "      <td>8.854163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>About 25 is correct for Numminen and Lumme. ...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>10.796824</td>\n",
       "      <td>9.588423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am in the market for a 24-bit graphics card...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>8.231452</td>\n",
       "      <td>8.060416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I hope you realize that for a cellular phone,...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>12.691465</td>\n",
       "      <td>6.590484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes.   Please describe these \"number of ways\"...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>12.448191</td>\n",
       "      <td>10.167531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text SUBSET    label  \\\n",
       "0    Well, it's been a while since this was discu...    raw  ABSTAIN   \n",
       "1    About 25 is correct for Numminen and Lumme. ...    raw  ABSTAIN   \n",
       "2   I am in the market for a 24-bit graphics card...    raw  ABSTAIN   \n",
       "3   I hope you realize that for a cellular phone,...    raw  ABSTAIN   \n",
       "4   Yes.   Please describe these \"number of ways\"...    raw  ABSTAIN   \n",
       "\n",
       "   embed_2d_0  embed_2d_1  \n",
       "0    8.699749    8.854163  \n",
       "1   10.796824    9.588423  \n",
       "2    8.231452    8.060416  \n",
       "3   12.691465    6.590484  \n",
       "4   12.448191   10.167531  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any kwargs will be passed onto the corresponding reduction\n",
    "# for umap: https://umap-learn.readthedocs.io/en/latest/parameters.html\n",
    "# for ivis: https://bering-ivis.readthedocs.io/en/latest/api.html\n",
    "reducer = dataset.compute_nd_embedding(vectorizer, \"umap\", dimension=2)\n",
    "\n",
    "# what we did adds 'embed_2d_0' and 'embed_2d_1' columns to the DataFrames in dataset.dfs\n",
    "dataset.dfs[\"raw\"]().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c2dc51",
   "metadata": {},
   "source": [
    "## :sparkles: **Apply Labels**\n",
    "\n",
    "We are ready for the annotation interface!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b1c0bbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T01:59:51.986707Z",
     "iopub.status.busy": "2023-06-06T01:59:51.986454Z",
     "iopub.status.idle": "2023-06-06T01:59:52.086356Z",
     "shell.execute_reply": "2023-06-06T01:59:52.084696Z"
    }
   },
   "outputs": [],
   "source": [
    "from hover.recipes.stable import simple_annotator\n",
    "\n",
    "interactive_plot = simple_annotator(dataset)\n",
    "\n",
    "# ---------- NOTEBOOK MODE: for your actual Jupyter environment ---------\n",
    "# this code will render the entire plot in Jupyter\n",
    "# from bokeh.io import show, output_notebook\n",
    "# output_notebook()\n",
    "# show(interactive_plot, notebook_url='https://localhost:8888')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ae51f0",
   "metadata": {},
   "source": [
    "-   <details open><summary>Tips: annotation interface basics</summary>\n",
    "    <details open><summary>Video guide</summary>\n",
    "        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/WYN2WduzJWg\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Text guide</summary>\n",
    "        There should be a `SupervisableDataset` board on the left and an `BokehDataAnnotator` on the right, each with a few buttons.\n",
    "\n",
    "        === \"SupervisableDataset\"\n",
    "            -   `push`: push `Dataset` updates to the bokeh plots.\n",
    "            -   `commit`: add data entries selected in the `Annotator` to a specified subset.\n",
    "            -   `dedup`: deduplicate across subsets by `feature` (last in gets kept).\n",
    "            -   `export`: save your data (all subsets) in a specified format.\n",
    "\n",
    "        === \"BokehDataAnnotator\"\n",
    "            -   `raw`/`train`/`dev`/`test`: choose which subsets to display or hide.\n",
    "            -   `apply`: apply the `label` input to the selected points in the `raw` subset only.\n",
    "\n",
    "        We've essentially put the data into neighborboods based on the vectorizer, but the quality (homogeneity of labels) of such neighborhoods can vary.\n",
    "\n",
    "        -   hover over any data point to see its tooltip.\n",
    "        -   take advantage of different selection tools to apply labels at appropriate scales.\n",
    "        -   the search widget might turn out useful.\n",
    "            -    note that it does not select points but highlights them.\n",
    "    </details>\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
