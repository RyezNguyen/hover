{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08b56199",
   "metadata": {},
   "source": [
    "> Welcome to the basic use case of `hover`!\n",
    ">\n",
    "> :sunglasses: Let's say we want to label some data and call it a day.\n",
    "\n",
    "-   <details open><summary>Dependencies for {== local environments ==}</summary>\n",
    "    When you run the code locally, you may need to install additional packages.\n",
    "\n",
    "    To run the text embedding code on this page, you need:\n",
    "```shell\n",
    "    pip install spacy\n",
    "    python -m spacy download en_core_web_md\n",
    "```\n",
    "\n",
    "    To render `bokeh` plots in Jupyter, you need:\n",
    "```shell\n",
    "    pip install jupyter_bokeh\n",
    "```\n",
    "\n",
    "    If you are using JupyterLab older than 3.0, use this instead ([reference](https://pypi.org/project/jupyter-bokeh/)):\n",
    "```shell\n",
    "    jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "    jupyter labextension install @bokeh/jupyter_bokeh\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "## **Ingredient 1 / 3: Raw Data**\n",
    "\n",
    "Start with a spreadsheet loaded in `pandas`.\n",
    "\n",
    "We turn it into a [`SupervisableDataset`](../../reference/core-dataset/#hover.core.dataset.SupervisableDataset) designed for labeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578bb999",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T01:24:56.591489Z",
     "iopub.status.busy": "2023-11-28T01:24:56.591014Z",
     "iopub.status.idle": "2023-11-28T01:24:58.271652Z",
     "shell.execute_reply": "2023-11-28T01:24:58.271060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: Initializing</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: Initializing\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: Deduplicating</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: Deduplicating\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: --subset raw rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">978</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: --subset raw rows: \u001b[0m\u001b[1;36m1000\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m978\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: --subset train rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: --subset train rows: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: --subset dev rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: --subset dev rows: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: --subset test rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: --subset test rows: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">游릭 SupervisableTextDataset: Set up label encoder/decoder with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008000; text-decoration-color: #008000\"> classes.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m游릭 SupervisableTextDataset: Set up label encoder/decoder with \u001b[0m\u001b[1;36m0\u001b[0m\u001b[32m classes.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">游릭 SupervisableTextDataset: Population updater: latest population with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008000; text-decoration-color: #008000\"> classes.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m游릭 SupervisableTextDataset: Population updater: latest population with \u001b[0m\u001b[1;36m0\u001b[0m\u001b[32m classes.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: finished setting up bokeh elements.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: finished setting up bokeh elements.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">游릭 SupervisableTextDataset: finished initialization.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m游릭 SupervisableTextDataset: finished initialization.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>SUBSET</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I just wanted to let everyone know that I have...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[In looking through my files this weekend, I r...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Any prize like this is going to need to be wo...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: Re: Eugenics / ;Probably within 50 ye...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes, I do agree with your definition.  My use...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text SUBSET    label\n",
       "0  I just wanted to let everyone know that I have...    raw  ABSTAIN\n",
       "1  [In looking through my files this weekend, I r...    raw  ABSTAIN\n",
       "2   Any prize like this is going to need to be wo...    raw  ABSTAIN\n",
       "3  Subject: Re: Eugenics / ;Probably within 50 ye...    raw  ABSTAIN\n",
       "4   Yes, I do agree with your definition.  My use...    raw  ABSTAIN"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hover.core.dataset import SupervisableTextDataset\n",
    "import pandas as pd\n",
    "\n",
    "example_csv_path = \"https://raw.githubusercontent.com/phurwicz/hover-gallery/main/0.5.0/20_newsgroups_raw.csv\"\n",
    "# for fast, low-memory demonstration purpose, sample the data\n",
    "df_raw = pd.read_csv(example_csv_path).sample(1000)\n",
    "df_raw[\"text\"] = df_raw[\"text\"].astype(str)\n",
    "\n",
    "# data is divided into 4 subsets: \"raw\" / \"train\" / \"dev\" / \"test\"\n",
    "# this example assumes no labeled data available., i.e. only \"raw\"\n",
    "df_raw[\"SUBSET\"] = \"raw\"\n",
    "\n",
    "# this class stores the dataset throught the labeling process\n",
    "dataset = SupervisableTextDataset.from_pandas(df_raw, feature_key=\"text\", label_key=\"label\")\n",
    "\n",
    "# each subset can be accessed as its own DataFrame\n",
    "dataset.dfs[\"raw\"]().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff36405",
   "metadata": {},
   "source": [
    "-   <details open><summary>FAQ</summary>\n",
    "    <details open><summary>What if I have multiple features?</summary>\n",
    "        `feature_key` refers to the field that will be vectorized later on, which can be a JSON that encloses multiple features.\n",
    "\n",
    "        For example, suppose our data entries look like this:\n",
    "```python\n",
    "        {\"f1\": \"foo\", \"f2\": \"bar\", \"non_feature\": \"abc\"}\n",
    "```\n",
    "\n",
    "        We can put `f1` and `f2` in a JSON and convert the entries like this:\n",
    "```python\n",
    "        # could also keep f1 and f2 around\n",
    "        {'feature': '{\"f1\": \"foo\", \"f2\": \"bar\"}', 'non_feature': 'abc'}\n",
    "```\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Can I use audio or image data?</summary>\n",
    "        Yes! Please check out the \"Guides\" section of the documentation.\n",
    "    </details>\n",
    "\n",
    "</details>\n",
    "\n",
    "## **Ingredient 2 / 3: Embedding**\n",
    "\n",
    "A pre-trained embedding lets us group data points semantically.\n",
    "\n",
    "In particular, let's define a `data -> embedding vector` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a00a398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T01:24:58.274670Z",
     "iopub.status.busy": "2023-11-28T01:24:58.274140Z",
     "iopub.status.idle": "2023-11-28T01:25:01.147994Z",
     "shell.execute_reply": "2023-11-28T01:25:01.147340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I just wanted to let everyone know that I have lost what little respect I have for Jim LeFebvre after seeing today's Cubs game. First of all how could he start Maldonado over May. After the way May played at the end of last year and the way he tore up the Cactus League how could you let him sit the bench? Not to mention that a right hander (Maddux) started. I really blew my top when Lefebvre pinch hit for Rick Wilkins with TOMMY SHIELDS! How can you do that just because of the lefty-righty thing, too much is made of that. Wilkins is twice the hitter that Shields is. Then the next batter was Jose Vizcaino, one of the weakest hitters I have ever seen, and who had looked terrible at bat all day, and Lefebre let him hit, while May still sat the bench. I think even Arnie Harris was stunned by this because he showed May sitting in the dugout while Vizcaino was batting. Face it Lefebvre has got to be the worst manager in baseball.       A dishard Cub fan \n",
      "Vector shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "from functools import lru_cache\n",
    "\n",
    "# use your preferred embedding for the task\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# raw data (str in this case) -> np.array\n",
    "@lru_cache(maxsize=int(1e+4))\n",
    "def vectorizer(text):\n",
    "    clean_text = re.sub(r\"[\\s]+\", r\" \", str(text))\n",
    "    return nlp(clean_text, disable=nlp.pipe_names).vector\n",
    "\n",
    "text = dataset.dfs[\"raw\"]().loc[0, \"text\"]\n",
    "vec = vectorizer(text)\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Vector shape: {vec.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411a2e0b",
   "metadata": {},
   "source": [
    "-   <details open><summary>Tips</summary>\n",
    "    <details open><summary>Caching</summary>\n",
    "        `dataset` by itself stores the original features but not the corresponding vectors.\n",
    "\n",
    "        To avoid vectorizing the same feature again and again, we could simply do:\n",
    "```python\n",
    "        from functools import cache\n",
    "\n",
    "        @cache\n",
    "        def vectorizer(feature):\n",
    "            # put code here\n",
    "```\n",
    "\n",
    "        If you'd like to limit the size of the cache, something like `@lru_cache(maxsize=10000)` could help.\n",
    "\n",
    "        Check out [functools](https://docs.python.org/3/library/functools.html) for more options.\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Vectorizing multiple features</summary>\n",
    "        Suppose we have multiple features enclosed in a JSON:\n",
    "```python\n",
    "        # could also keep f1 and f2 around\n",
    "        {'feature': '{\"f1\": \"foo\", \"f2\": \"bar\"}', 'non_feature': 'abc'}\n",
    "```\n",
    "\n",
    "        Also, suppose we have individual vectorizers likes this:\n",
    "```python\n",
    "        def vectorizer_1(feature_1):\n",
    "            # put code here\n",
    "\n",
    "        def vectorizer_2(feature_2):\n",
    "            # put code here\n",
    "```\n",
    "\n",
    "        Then we can define a composite vectorizer:\n",
    "```python\n",
    "        import json\n",
    "        import numpy as np\n",
    "\n",
    "        def vectorizer(feature_json):\n",
    "            data_dict = json.loads(feature_json)\n",
    "            vectors = []\n",
    "            for field, func in [\n",
    "                (\"f1\", vectorizer_1),\n",
    "                (\"f2\", vectorizer_2),\n",
    "            ]:\n",
    "                vectors.append(func(data_dict[field]))\n",
    "\n",
    "            return np.concatenate(vectors)\n",
    "```\n",
    "    </details>\n",
    "\n",
    "</details>\n",
    "\n",
    "## **Ingredient 3 / 3: 2D Embedding**\n",
    "\n",
    "We compute a 2D version of the pre-trained embedding to visualize the whole dataset.\n",
    "\n",
    "Hover has built-in methods for calling [umap](https://umap-learn.readthedocs.io/en/latest/) or [ivis](https://bering-ivis.readthedocs.io/en/latest/).\n",
    "\n",
    "-   <details open><summary>Dependencies (when in your own environment)</summary>\n",
    "    The libraries for this step are not directly required by `hover`:\n",
    "\n",
    "    -   for umap: `pip install umap-learn`\n",
    "    -   for ivis: `pip install ivis[cpu]` or `pip install ivis[gpu]`\n",
    "\n",
    "    `umap-learn` is installed in this demo environment.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877cf182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T01:25:01.150866Z",
     "iopub.status.busy": "2023-11-28T01:25:01.150396Z",
     "iopub.status.idle": "2023-11-28T01:25:24.095470Z",
     "shell.execute_reply": "2023-11-28T01:25:24.094859Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 978/978 [00:02<00:00, 436.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: Fit-transforming UMAP on </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">978</span><span style=\"color: #000080; text-decoration-color: #000080\"> samples</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: Fit-transforming UMAP on \u001b[0m\u001b[1;36m978\u001b[0m\u001b[34m samples\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: Transforming UMAP on </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> samples</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: Transforming UMAP on \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m samples\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">游릭 SupervisableTextDataset: Computed </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #008000; text-decoration-color: #008000\">-d embedding in columns </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'embed_2d_0'</span><span style=\"color: #008000; text-decoration-color: #008000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'embed_2d_1'</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m游릭 SupervisableTextDataset: Computed \u001b[0m\u001b[1;36m2\u001b[0m\u001b[32m-d embedding in columns \u001b[0m\u001b[1;32m[\u001b[0m\u001b[32m'embed_2d_0'\u001b[0m\u001b[32m, \u001b[0m\u001b[32m'embed_2d_1'\u001b[0m\u001b[1;32m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>SUBSET</th>\n",
       "      <th>label</th>\n",
       "      <th>embed_2d_0</th>\n",
       "      <th>embed_2d_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I just wanted to let everyone know that I have...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>12.359913</td>\n",
       "      <td>6.951601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[In looking through my files this weekend, I r...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>14.182671</td>\n",
       "      <td>6.663335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Any prize like this is going to need to be wo...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>14.028653</td>\n",
       "      <td>8.299442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: Re: Eugenics / ;Probably within 50 ye...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>12.322807</td>\n",
       "      <td>10.045153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes, I do agree with your definition.  My use...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>13.050087</td>\n",
       "      <td>9.912058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text SUBSET    label  \\\n",
       "0  I just wanted to let everyone know that I have...    raw  ABSTAIN   \n",
       "1  [In looking through my files this weekend, I r...    raw  ABSTAIN   \n",
       "2   Any prize like this is going to need to be wo...    raw  ABSTAIN   \n",
       "3  Subject: Re: Eugenics / ;Probably within 50 ye...    raw  ABSTAIN   \n",
       "4   Yes, I do agree with your definition.  My use...    raw  ABSTAIN   \n",
       "\n",
       "   embed_2d_0  embed_2d_1  \n",
       "0   12.359913    6.951601  \n",
       "1   14.182671    6.663335  \n",
       "2   14.028653    8.299442  \n",
       "3   12.322807   10.045153  \n",
       "4   13.050087    9.912058  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any kwargs will be passed onto the corresponding reduction\n",
    "# for umap: https://umap-learn.readthedocs.io/en/latest/parameters.html\n",
    "# for ivis: https://bering-ivis.readthedocs.io/en/latest/api.html\n",
    "reducer = dataset.compute_nd_embedding(vectorizer, \"umap\", dimension=2)\n",
    "\n",
    "# what we did adds 'embed_2d_0' and 'embed_2d_1' columns to the DataFrames in dataset.dfs\n",
    "dataset.dfs[\"raw\"]().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2cff64",
   "metadata": {},
   "source": [
    "## :sparkles: **Apply Labels**\n",
    "\n",
    "We are ready for the annotation interface!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "730dbd6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T01:25:24.098400Z",
     "iopub.status.busy": "2023-11-28T01:25:24.098011Z",
     "iopub.status.idle": "2023-11-28T01:25:24.182488Z",
     "shell.execute_reply": "2023-11-28T01:25:24.181866Z"
    }
   },
   "outputs": [],
   "source": [
    "from hover.recipes.stable import simple_annotator\n",
    "\n",
    "interactive_plot = simple_annotator(dataset)\n",
    "\n",
    "# ---------- NOTEBOOK MODE: for your actual Jupyter environment ---------\n",
    "# this code will render the entire plot in Jupyter\n",
    "# from bokeh.io import show, output_notebook\n",
    "# output_notebook()\n",
    "# show(interactive_plot, notebook_url='https://localhost:8888')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a976ef6c",
   "metadata": {},
   "source": [
    "-   <details open><summary>Tips: annotation interface basics</summary>\n",
    "    <details open><summary>Video guide</summary>\n",
    "        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/WYN2WduzJWg\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Text guide</summary>\n",
    "        There should be a `SupervisableDataset` board on the left and an `BokehDataAnnotator` on the right, each with a few buttons.\n",
    "\n",
    "        === \"SupervisableDataset\"\n",
    "            -   `push`: push `Dataset` updates to the bokeh plots.\n",
    "            -   `commit`: add data entries selected in the `Annotator` to a specified subset.\n",
    "            -   `dedup`: deduplicate across subsets by `feature` (last in gets kept).\n",
    "            -   `export`: save your data (all subsets) in a specified format.\n",
    "\n",
    "        === \"BokehDataAnnotator\"\n",
    "            -   `raw`/`train`/`dev`/`test`: choose which subsets to display or hide.\n",
    "            -   `apply`: apply the `label` input to the selected points in the `raw` subset only.\n",
    "\n",
    "        We've essentially put the data into neighborboods based on the vectorizer, but the quality (homogeneity of labels) of such neighborhoods can vary.\n",
    "\n",
    "        -   hover over any data point to see its tooltip.\n",
    "        -   take advantage of different selection tools to apply labels at appropriate scales.\n",
    "        -   the search widget might turn out useful.\n",
    "            -    note that it does not select points but highlights them.\n",
    "    </details>\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
