{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41b657de",
   "metadata": {},
   "source": [
    "> Welcome to the basic use case of `hover`!\n",
    ">\n",
    "> :sunglasses: Let's say we want to label some data and call it a day.\n",
    "\n",
    "-   <details open><summary>Dependencies for {== local environments ==}</summary>\n",
    "    When you run the code locally, you may need to install additional packages.\n",
    "\n",
    "    To run the text embedding code on this page, you need:\n",
    "```shell\n",
    "    pip install spacy\n",
    "    python -m spacy download en_core_web_md\n",
    "```\n",
    "\n",
    "    To render `bokeh` plots in Jupyter, you need:\n",
    "```shell\n",
    "    pip install jupyter_bokeh\n",
    "```\n",
    "\n",
    "    If you are using JupyterLab older than 3.0, use this instead ([reference](https://pypi.org/project/jupyter-bokeh/)):\n",
    "```shell\n",
    "    jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "    jupyter labextension install @bokeh/jupyter_bokeh\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "## **Ingredient 1 / 3: Raw Data**\n",
    "\n",
    "Start with a spreadsheet loaded in `pandas`.\n",
    "\n",
    "We turn it into a [`SupervisableDataset`](../../reference/core-dataset/#hover.core.dataset.SupervisableDataset) designed for labeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6795f0e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T01:21:54.707111Z",
     "iopub.status.busy": "2023-11-14T01:21:54.706915Z",
     "iopub.status.idle": "2023-11-14T01:21:56.383520Z",
     "shell.execute_reply": "2023-11-14T01:21:56.382924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: Initializing</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: Initializing\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: Deduplicating</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: Deduplicating\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: --subset raw rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">980</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: --subset raw rows: \u001b[0m\u001b[1;36m1000\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m980\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: --subset train rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: --subset train rows: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: --subset dev rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: --subset dev rows: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: --subset test rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: --subset test rows: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">游릭 SupervisableTextDataset: Set up label encoder/decoder with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008000; text-decoration-color: #008000\"> classes.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m游릭 SupervisableTextDataset: Set up label encoder/decoder with \u001b[0m\u001b[1;36m0\u001b[0m\u001b[32m classes.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">游릭 SupervisableTextDataset: Population updater: latest population with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008000; text-decoration-color: #008000\"> classes.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m游릭 SupervisableTextDataset: Population updater: latest population with \u001b[0m\u001b[1;36m0\u001b[0m\u001b[32m classes.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: finished setting up bokeh elements.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: finished setting up bokeh elements.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">游릭 SupervisableTextDataset: finished initialization.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m游릭 SupervisableTextDataset: finished initialization.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>SUBSET</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Archive-name: space/addresses Last-modified: $...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Have you gotten an answer yet?  Using your va...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I took an alcohol server's class a few years...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:  (lots of stuff about the Nicene Creed delet...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why \"must\"?  ---           \" Whatever promi...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text SUBSET    label\n",
       "0  Archive-name: space/addresses Last-modified: $...    raw  ABSTAIN\n",
       "1   Have you gotten an answer yet?  Using your va...    raw  ABSTAIN\n",
       "2    I took an alcohol server's class a few years...    raw  ABSTAIN\n",
       "3  :  (lots of stuff about the Nicene Creed delet...    raw  ABSTAIN\n",
       "4     Why \"must\"?  ---           \" Whatever promi...    raw  ABSTAIN"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hover.core.dataset import SupervisableTextDataset\n",
    "import pandas as pd\n",
    "\n",
    "example_csv_path = \"https://raw.githubusercontent.com/phurwicz/hover-gallery/main/0.5.0/20_newsgroups_raw.csv\"\n",
    "# for fast, low-memory demonstration purpose, sample the data\n",
    "df_raw = pd.read_csv(example_csv_path).sample(1000)\n",
    "df_raw[\"text\"] = df_raw[\"text\"].astype(str)\n",
    "\n",
    "# data is divided into 4 subsets: \"raw\" / \"train\" / \"dev\" / \"test\"\n",
    "# this example assumes no labeled data available., i.e. only \"raw\"\n",
    "df_raw[\"SUBSET\"] = \"raw\"\n",
    "\n",
    "# this class stores the dataset throught the labeling process\n",
    "dataset = SupervisableTextDataset.from_pandas(df_raw, feature_key=\"text\", label_key=\"label\")\n",
    "\n",
    "# each subset can be accessed as its own DataFrame\n",
    "dataset.dfs[\"raw\"]().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf25fb0",
   "metadata": {},
   "source": [
    "-   <details open><summary>FAQ</summary>\n",
    "    <details open><summary>What if I have multiple features?</summary>\n",
    "        `feature_key` refers to the field that will be vectorized later on, which can be a JSON that encloses multiple features.\n",
    "\n",
    "        For example, suppose our data entries look like this:\n",
    "```python\n",
    "        {\"f1\": \"foo\", \"f2\": \"bar\", \"non_feature\": \"abc\"}\n",
    "```\n",
    "\n",
    "        We can put `f1` and `f2` in a JSON and convert the entries like this:\n",
    "```python\n",
    "        # could also keep f1 and f2 around\n",
    "        {'feature': '{\"f1\": \"foo\", \"f2\": \"bar\"}', 'non_feature': 'abc'}\n",
    "```\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Can I use audio or image data?</summary>\n",
    "        Yes! Please check out the \"Guides\" section of the documentation.\n",
    "    </details>\n",
    "\n",
    "</details>\n",
    "\n",
    "## **Ingredient 2 / 3: Embedding**\n",
    "\n",
    "A pre-trained embedding lets us group data points semantically.\n",
    "\n",
    "In particular, let's define a `data -> embedding vector` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a0a8ce0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T01:21:56.386447Z",
     "iopub.status.busy": "2023-11-14T01:21:56.386012Z",
     "iopub.status.idle": "2023-11-14T01:21:59.277287Z",
     "shell.execute_reply": "2023-11-14T01:21:59.276514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Archive-name: space/addresses Last-modified: $Date: 93/04/01 14:38:55 $  CONTACTING NASA, ESA, AND OTHER SPACE AGENCIES/COMPANIES  Many space activities center around large Government or International Bureaucracies. In the US that means NASA.  If you have basic information requests: (e.g., general PR info, research grants, data, limited tours, and ESPECIALLY SUMMER EMPLOYMENT (typically resumes should be ready by Jan.  1), etc.), consider contacting the nearest NASA Center to answer your questions.  EMail typically will not get you any where, computers are used by investigators, not PR people. The typical volume of mail per Center is a multiple of 10,000 letters a day. Seek the Public Information Office at one of the below, this is their job:  NASA (The National Aeronautics and Space Administration) is the civilian space agency of of the United States Federal Government. It reports directly to the White House and is not a Cabinet post such as the military Department of Defense.  Its 20K+ employees are civil servants and hence US citizens.  Another 100K+ contractors also work for NASA.  NASA CENTERS      NASA Headquarters (NASA HQ)     Washington DC 20546     (202)-358-1600   Ask them questions about policy, money, and things of political  nature. Direct specific questions to the appropriate center.      NASA Ames Research Center (ARC)     Moffett Field, CA 94035     (415)-694-5091   Some aeronautical research, atmosphere reentry, Mars and Venus  planetary atmospheres. \"Lead center\" for Helicopter research,  V/STOL, etc. Runs Pioneer series of space probes.      NASA Ames Research Center     Dryden Flight Research Facility [DFRF]     P. O. Box 273     Edwards, CA  93523     (805)-258-8381   Aircraft, mostly. Tested the shuttle orbiter landing  characteristics. Developed X-1, D-558, X-3, X-4, X-5, XB-70, and of  course, the X-15.      NASA Goddard Space Flight Center (GSFC)     Greenbelt, MD 20771     [Outside of Washington DC]     (301)-344-6255   Earth orbiting unmanned satellites and sounding rockets. Developed  LANDSAT.      Jet Propulsion Laboratory (JPL)     California Institute of Technology     4800 Oak Grove Dr.     Pasadena, CA 91109     (818)-354-5011   The \"heavies\" in planetary research probes and other unmanned  projects (they also had a lot to do with IRAS). They run Voyager,  Magellan, Galileo, and will run Cassini, CRAF, etc. etc.. For  images, probe navigation, and other info about unmanned exploration,  this is the place to go.   JPL is run under contract for NASA by the nearby California  Institute of Technology, unlike the NASA centers above. This  distinction is subtle but critical. JPL has different requirements  for unsolicited research proposals and summer hires. For instance in  the latter, an SF 171 is useless. Employees are Caltech employees,  contractors, and for the most part have similar responsibilities.  They offer an alternative to funding after other NASA Centers.   A fact sheet and description of JPL is available by anonymous  FTP in       ames.arc.nasa.gov:pub/SPACE/FAQ/JPLDescription      NASA Johnson Manned Space Center (JSC)     Houston, TX 77058     (713)-483-5111   JSC manages Space Shuttle, ground control of manned missions.  Astronaut training. Manned mission simulators.      NASA Kennedy Space Flight Center (KSC)     Titusville, FL 32899     (407)-867-2468   Space launch center. You know this one.      NASA Langley Research Center (LaRC)     Hampton, VA 23665     [Near Newport News, VA]     (804)-865-2935   Original NASA site. Specializes in theoretical and experimental  flight dynamics. Viking. Long Duration Exposure Facility.      NASA Lewis Research Center (LeRC)     21000 Brookpark Rd.     Cleveland, OH 44135     (216)-433-4000   Aircraft/Rocket propulsion. Space power generation. Materials  research.      NASA Marshall Space Flight Center (MSFC)     Huntsville, AL 35812     (205)-453-0034   Development, production, delivery of Solid Rocket Boosters, External  Tank, Orbiter main engines. Propulsion and launchers.      Michoud Assembly Facility     Orleans Parish     New Orleans, LA 70129     (504)-255-2601   Shuttle external tanks are produced here; formerly Michoud produced  first stages for the Saturn V.      Stennis Space Center     Bay St. Louis, Mississippi 39529     (601)-688-3341   Space Shuttle main engines are tested here, as were Saturn V first  and second stages. The center also does remote-sensing and  technology-transfer research.      Wallops Flight Center     Wallops Island, VA 23337     (804)824-3411      Aeronautical research, sounding rockets, Scout launcher.      Manager, Technology Utilization Office     NASA Scientific and Technical Information Facility     Post Office Box 8757     Baltimore, Maryland 21240      Specific requests for software must go thru COSMIC at the Univ. of     Georgia, NASA's contracted software redistribution service. You can     reach them at cosmic@uga.bitnet.      NOTE: Foreign nationals requesting information must go through their     Embassies in Washington DC. These are facilities of the US Government     and are regarded with some degree of economic sensitivity. Centers     cannot directly return information without high Center approval. Allow     at least 1 month for clearance. This includes COSMIC.  The US Air Force Space Command can be contacted thru the Pentagon along with     other Department of Defense offices. They have unacknowledged offices in     Los Angeles, Sunnyvale, Colorado Springs, and other locations. They have     a budget which rivals NASA in size.  ARIANESPACE HEADQUARTERS     Boulevard de l'Europe     B.P. 177     91006 Evry Cedex     France  ARIANESPACE, INC.     1747 Pennsylvania Avenue, NW Suite 875     Washington, DC 20006     (202)-728-9075  EUROPEAN SPACE AGENCY (ESA)     955 L'Enfant Plaza S.W.     Washington, D.C. 20024     (202)-488-4158  NATIONAL SPACE DEVELOPMENT AGENCY (NASDA)     4-1 Hamamatsu-Cho, 2 Chome     Minato-Ku, Tokyo 105, JAPAN  SOYUZKARTA     45 Vologradsij Pr.     Moscow 109125     USSR  SPACE CAMP     Alabama Space and Rocket Center U.S. SPACE CAMP     1 Tranquility Base   6225 Vectorspace Blvd     Huntsville, AL 35805  Titusville FL  32780     (205)-837-3400   (407)267-3184      Registration and mailing list are handled through Huntsville -- both     camps are described in the same brochure.      Programs offered at Space Camp are:   Space Camp - one week, youngsters completing grades 4-6  Space Academy I - one week, grades 7-9  Aviation Challenge - one week high school program, grades 9-11  Space Academy II - 8 days, college accredited, grades 10-12  Adult Program - 3 days (editorial comment: it's great!)  Teachers Program - 5 days  SPACE COMMERCE CORPORATION (U.S. agent for Soviet launch services)     504 Pluto Drive      69th flr, Texas Commerce Tower     Colorado Springs, CO 80906     Houston, TX 77002     (719)-578-5490      (713)-227-9000  SPACEHAB     600 Maryland Avenue, SW     Suite 201 West     Washington, DC 20004     (202)-488-3483  SPOT IMAGE CORPORATION     1857 Preston White Drive,     Reston, VA 22091     (FAX) (703)-648-1813    (703)-620-2200   OTHER COMMERCIAL SPACE BUSINESSES      Vincent Cate maintains a list with addresses and some info for a variety of companies in space-related businesses. This is mailed out on the space-investors list he runs (see the \"Network Resources\" FAQ) and is also available by anonymous ftp from furmint.nectar.cs.cmu.edu (128.2.209.111) in /usr/vac/ftp/space-companies. \n",
      "Vector shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "from functools import lru_cache\n",
    "\n",
    "# use your preferred embedding for the task\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# raw data (str in this case) -> np.array\n",
    "@lru_cache(maxsize=int(1e+4))\n",
    "def vectorizer(text):\n",
    "    clean_text = re.sub(r\"[\\s]+\", r\" \", str(text))\n",
    "    return nlp(clean_text, disable=nlp.pipe_names).vector\n",
    "\n",
    "text = dataset.dfs[\"raw\"]().loc[0, \"text\"]\n",
    "vec = vectorizer(text)\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Vector shape: {vec.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4b0827",
   "metadata": {},
   "source": [
    "-   <details open><summary>Tips</summary>\n",
    "    <details open><summary>Caching</summary>\n",
    "        `dataset` by itself stores the original features but not the corresponding vectors.\n",
    "\n",
    "        To avoid vectorizing the same feature again and again, we could simply do:\n",
    "```python\n",
    "        from functools import cache\n",
    "\n",
    "        @cache\n",
    "        def vectorizer(feature):\n",
    "            # put code here\n",
    "```\n",
    "\n",
    "        If you'd like to limit the size of the cache, something like `@lru_cache(maxsize=10000)` could help.\n",
    "\n",
    "        Check out [functools](https://docs.python.org/3/library/functools.html) for more options.\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Vectorizing multiple features</summary>\n",
    "        Suppose we have multiple features enclosed in a JSON:\n",
    "```python\n",
    "        # could also keep f1 and f2 around\n",
    "        {'feature': '{\"f1\": \"foo\", \"f2\": \"bar\"}', 'non_feature': 'abc'}\n",
    "```\n",
    "\n",
    "        Also, suppose we have individual vectorizers likes this:\n",
    "```python\n",
    "        def vectorizer_1(feature_1):\n",
    "            # put code here\n",
    "\n",
    "        def vectorizer_2(feature_2):\n",
    "            # put code here\n",
    "```\n",
    "\n",
    "        Then we can define a composite vectorizer:\n",
    "```python\n",
    "        import json\n",
    "        import numpy as np\n",
    "\n",
    "        def vectorizer(feature_json):\n",
    "            data_dict = json.loads(feature_json)\n",
    "            vectors = []\n",
    "            for field, func in [\n",
    "                (\"f1\", vectorizer_1),\n",
    "                (\"f2\", vectorizer_2),\n",
    "            ]:\n",
    "                vectors.append(func(data_dict[field]))\n",
    "\n",
    "            return np.concatenate(vectors)\n",
    "```\n",
    "    </details>\n",
    "\n",
    "</details>\n",
    "\n",
    "## **Ingredient 3 / 3: 2D Embedding**\n",
    "\n",
    "We compute a 2D version of the pre-trained embedding to visualize the whole dataset.\n",
    "\n",
    "Hover has built-in methods for calling [umap](https://umap-learn.readthedocs.io/en/latest/) or [ivis](https://bering-ivis.readthedocs.io/en/latest/).\n",
    "\n",
    "-   <details open><summary>Dependencies (when in your own environment)</summary>\n",
    "    The libraries for this step are not directly required by `hover`:\n",
    "\n",
    "    -   for umap: `pip install umap-learn`\n",
    "    -   for ivis: `pip install ivis[cpu]` or `pip install ivis[gpu]`\n",
    "\n",
    "    `umap-learn` is installed in this demo environment.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e19a156e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T01:21:59.279966Z",
     "iopub.status.busy": "2023-11-14T01:21:59.279680Z",
     "iopub.status.idle": "2023-11-14T01:22:22.024245Z",
     "shell.execute_reply": "2023-11-14T01:22:22.023583Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 980/980 [00:02<00:00, 441.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: Fit-transforming UMAP on </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">980</span><span style=\"color: #000080; text-decoration-color: #000080\"> samples</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: Fit-transforming UMAP on \u001b[0m\u001b[1;36m980\u001b[0m\u001b[34m samples\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: Transforming UMAP on </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> samples</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: Transforming UMAP on \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m samples\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">游릭 SupervisableTextDataset: Computed </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #008000; text-decoration-color: #008000\">-d embedding in columns </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'embed_2d_0'</span><span style=\"color: #008000; text-decoration-color: #008000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'embed_2d_1'</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m游릭 SupervisableTextDataset: Computed \u001b[0m\u001b[1;36m2\u001b[0m\u001b[32m-d embedding in columns \u001b[0m\u001b[1;32m[\u001b[0m\u001b[32m'embed_2d_0'\u001b[0m\u001b[32m, \u001b[0m\u001b[32m'embed_2d_1'\u001b[0m\u001b[1;32m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>SUBSET</th>\n",
       "      <th>label</th>\n",
       "      <th>embed_2d_0</th>\n",
       "      <th>embed_2d_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Archive-name: space/addresses Last-modified: $...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>7.907687</td>\n",
       "      <td>9.807972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Have you gotten an answer yet?  Using your va...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>8.783878</td>\n",
       "      <td>8.945389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I took an alcohol server's class a few years...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>12.903398</td>\n",
       "      <td>9.942797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:  (lots of stuff about the Nicene Creed delet...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>11.704416</td>\n",
       "      <td>12.979619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why \"must\"?  ---           \" Whatever promi...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>13.544121</td>\n",
       "      <td>12.919756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text SUBSET    label  \\\n",
       "0  Archive-name: space/addresses Last-modified: $...    raw  ABSTAIN   \n",
       "1   Have you gotten an answer yet?  Using your va...    raw  ABSTAIN   \n",
       "2    I took an alcohol server's class a few years...    raw  ABSTAIN   \n",
       "3  :  (lots of stuff about the Nicene Creed delet...    raw  ABSTAIN   \n",
       "4     Why \"must\"?  ---           \" Whatever promi...    raw  ABSTAIN   \n",
       "\n",
       "   embed_2d_0  embed_2d_1  \n",
       "0    7.907687    9.807972  \n",
       "1    8.783878    8.945389  \n",
       "2   12.903398    9.942797  \n",
       "3   11.704416   12.979619  \n",
       "4   13.544121   12.919756  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any kwargs will be passed onto the corresponding reduction\n",
    "# for umap: https://umap-learn.readthedocs.io/en/latest/parameters.html\n",
    "# for ivis: https://bering-ivis.readthedocs.io/en/latest/api.html\n",
    "reducer = dataset.compute_nd_embedding(vectorizer, \"umap\", dimension=2)\n",
    "\n",
    "# what we did adds 'embed_2d_0' and 'embed_2d_1' columns to the DataFrames in dataset.dfs\n",
    "dataset.dfs[\"raw\"]().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f4e341",
   "metadata": {},
   "source": [
    "## :sparkles: **Apply Labels**\n",
    "\n",
    "We are ready for the annotation interface!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60b05576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T01:22:22.027022Z",
     "iopub.status.busy": "2023-11-14T01:22:22.026692Z",
     "iopub.status.idle": "2023-11-14T01:22:22.365200Z",
     "shell.execute_reply": "2023-11-14T01:22:22.364485Z"
    }
   },
   "outputs": [],
   "source": [
    "from hover.recipes.stable import simple_annotator\n",
    "\n",
    "interactive_plot = simple_annotator(dataset)\n",
    "\n",
    "# ---------- NOTEBOOK MODE: for your actual Jupyter environment ---------\n",
    "# this code will render the entire plot in Jupyter\n",
    "# from bokeh.io import show, output_notebook\n",
    "# output_notebook()\n",
    "# show(interactive_plot, notebook_url='https://localhost:8888')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c069ee",
   "metadata": {},
   "source": [
    "-   <details open><summary>Tips: annotation interface basics</summary>\n",
    "    <details open><summary>Video guide</summary>\n",
    "        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/WYN2WduzJWg\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Text guide</summary>\n",
    "        There should be a `SupervisableDataset` board on the left and an `BokehDataAnnotator` on the right, each with a few buttons.\n",
    "\n",
    "        === \"SupervisableDataset\"\n",
    "            -   `push`: push `Dataset` updates to the bokeh plots.\n",
    "            -   `commit`: add data entries selected in the `Annotator` to a specified subset.\n",
    "            -   `dedup`: deduplicate across subsets by `feature` (last in gets kept).\n",
    "            -   `export`: save your data (all subsets) in a specified format.\n",
    "\n",
    "        === \"BokehDataAnnotator\"\n",
    "            -   `raw`/`train`/`dev`/`test`: choose which subsets to display or hide.\n",
    "            -   `apply`: apply the `label` input to the selected points in the `raw` subset only.\n",
    "\n",
    "        We've essentially put the data into neighborboods based on the vectorizer, but the quality (homogeneity of labels) of such neighborhoods can vary.\n",
    "\n",
    "        -   hover over any data point to see its tooltip.\n",
    "        -   take advantage of different selection tools to apply labels at appropriate scales.\n",
    "        -   the search widget might turn out useful.\n",
    "            -    note that it does not select points but highlights them.\n",
    "    </details>\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
