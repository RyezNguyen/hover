{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b851a3",
   "metadata": {},
   "source": [
    "> The most common usage of `hover` is through built-in `recipe`s like in the quickstart.\n",
    ">\n",
    "> :ferris_wheel: Let's explore another `recipe` -- an active learning example.\n",
    "\n",
    "-   <details open><summary>Dependencies for {== local environments ==}</summary>\n",
    "    When you run the code locally, you may need to install additional packages.\n",
    "\n",
    "    To run the text embedding code on this page, you need:\n",
    "```shell\n",
    "    pip install spacy\n",
    "    python -m spacy download en_core_web_md\n",
    "```\n",
    "\n",
    "    To render `bokeh` plots in Jupyter, you need:\n",
    "```shell\n",
    "    pip install jupyter_bokeh\n",
    "```\n",
    "\n",
    "    If you are using JupyterLab older than 3.0, use this instead ([reference](https://pypi.org/project/jupyter-bokeh/)):\n",
    "```shell\n",
    "    jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "    jupyter labextension install @bokeh/jupyter_bokeh\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "## **Fundamentals**\n",
    "\n",
    "Hover `recipe`s are functions that take a `SupervisableDataset` and return an annotation interface.\n",
    "\n",
    "The `SupervisableDataset` is assumed to have some data and embeddings.\n",
    "\n",
    "## **Recap: Data & Embeddings**\n",
    "\n",
    "Let's preprare a dataset with embeddings. This is almost the same as in the [quickstart](../t0-quickstart/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d4d820d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T01:24:52.872814Z",
     "iopub.status.busy": "2024-04-02T01:24:52.872611Z",
     "iopub.status.idle": "2024-04-02T01:24:54.858173Z",
     "shell.execute_reply": "2024-04-02T01:24:54.857522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Initializing</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Initializing\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Deduplicating</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Deduplicating\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset raw rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">369</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset raw rows: \u001b[0m\u001b[1;36m400\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m369\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset train rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset train rows: \u001b[0m\u001b[1;36m400\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m384\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset dev rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">97</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset dev rows: \u001b[0m\u001b[1;36m100\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m97\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset test rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset test rows: \u001b[0m\u001b[1;36m100\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m99\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: Set up label encoder/decoder with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span><span style=\"color: #008000; text-decoration-color: #008000\"> classes.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: Set up label encoder/decoder with \u001b[0m\u001b[1;36m20\u001b[0m\u001b[32m classes.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: Population updater: latest population with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span><span style=\"color: #008000; text-decoration-color: #008000\"> classes.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: Population updater: latest population with \u001b[0m\u001b[1;36m20\u001b[0m\u001b[32m classes.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: finished setting up bokeh elements.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: finished setting up bokeh elements.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: finished initialization.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: finished initialization.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hover.core.dataset import SupervisableTextDataset\n",
    "import pandas as pd\n",
    "\n",
    "raw_csv_path = \"https://raw.githubusercontent.com/phurwicz/hover-gallery/main/0.5.0/20_newsgroups_raw.csv\"\n",
    "train_csv_path = \"https://raw.githubusercontent.com/phurwicz/hover-gallery/main/0.5.0/20_newsgroups_train.csv\"\n",
    "\n",
    "# for fast, low-memory demonstration purpose, sample the data\n",
    "df_raw = pd.read_csv(raw_csv_path).sample(400)\n",
    "df_raw[\"SUBSET\"] = \"raw\"\n",
    "df_train = pd.read_csv(train_csv_path).sample(400)\n",
    "df_train[\"SUBSET\"] = \"train\"\n",
    "df_dev = pd.read_csv(train_csv_path).sample(100)\n",
    "df_dev[\"SUBSET\"] = \"dev\"\n",
    "df_test = pd.read_csv(train_csv_path).sample(100)\n",
    "df_test[\"SUBSET\"] = \"test\"\n",
    "\n",
    "# build overall dataframe and ensure feature type\n",
    "df = pd.concat([df_raw, df_train, df_dev, df_test])\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "\n",
    "# this class stores the dataset throught the labeling process\n",
    "dataset = SupervisableTextDataset.from_pandas(df, feature_key=\"text\", label_key=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8275e1d1",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45402f1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T01:24:54.861015Z",
     "iopub.status.busy": "2024-04-02T01:24:54.860542Z",
     "iopub.status.idle": "2024-04-02T01:24:57.570483Z",
     "shell.execute_reply": "2024-04-02T01:24:57.569741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Forgive me if this is a FAQ (I have checked the list but I cant find it).  I have a problem with the cursor within Xterm on MONO (not grayscale monitors) The problem is that when I have an character application that displays input fields in reverse video the Xterm text cursor gets lost on the edge of the input field.  The solution would appear to be to set the xterm cursor to a line rather than a block, but how do you do this. I can't find any means although various sources seem to indicate it can be done.  When the xterm loses the input focus the cursor becomes an outlined block. This would also be preferable but I can't seem to force this to be the default either.  Configuration is  : Motorola 88K X11R4  Please reply by email if poss.  Thank you    -- ----------------------------------------------------------------------------- Steve Weet - European Mis - Motorola Cellular Subscriber Group Beechgreen Court, Chineham, Basingstoke, HANTS England. Phone : +44 (0)256 790154  E-Mail  stevew@chineham.euro.csg.mot.com Fax   : +44 (0)256 817481  Mobile  : +44 (0)850 335105  Post : w10075     -- \n",
      "Vector shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "from functools import lru_cache\n",
    "\n",
    "# use your preferred embedding for the task\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# raw data (str in this case) -> np.array\n",
    "@lru_cache(maxsize=int(1e+4))\n",
    "def vectorizer(text):\n",
    "    clean_text = re.sub(r\"[\\s]+\", r\" \", str(text))\n",
    "    return nlp(clean_text, disable=nlp.pipe_names).vector\n",
    "\n",
    "text = dataset.dfs[\"raw\"]().loc[0, \"text\"]\n",
    "vec = vectorizer(text)\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Vector shape: {vec.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcd000d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba909ffa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T01:24:57.573490Z",
     "iopub.status.busy": "2024-04-02T01:24:57.572901Z",
     "iopub.status.idle": "2024-04-02T01:25:25.191183Z",
     "shell.execute_reply": "2024-04-02T01:25:25.190493Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:   0%|          | 0/949 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:   4%|â–         | 38/949 [00:00<00:02, 375.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:   8%|â–Š         | 76/949 [00:00<00:02, 374.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  12%|â–ˆâ–        | 114/949 [00:00<00:03, 262.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  18%|â–ˆâ–Š        | 174/949 [00:00<00:02, 362.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  24%|â–ˆâ–ˆâ–       | 232/949 [00:00<00:01, 428.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  29%|â–ˆâ–ˆâ–‰       | 279/949 [00:00<00:01, 439.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  34%|â–ˆâ–ˆâ–ˆâ–      | 326/949 [00:00<00:01, 389.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 369/949 [00:00<00:01, 397.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 422/949 [00:01<00:01, 433.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 478/949 [00:01<00:01, 468.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 527/949 [00:01<00:01, 411.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 582/949 [00:01<00:00, 432.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 645/949 [00:01<00:00, 483.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 712/949 [00:01<00:00, 532.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 778/949 [00:01<00:00, 568.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 837/949 [00:01<00:00, 571.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 909/949 [00:01<00:00, 614.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 949/949 [00:02<00:00, 436.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Fit-transforming UMAP on </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">850</span><span style=\"color: #000080; text-decoration-color: #000080\"> samples</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Fit-transforming UMAP on \u001b[0m\u001b[1;36m850\u001b[0m\u001b[34m samples\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Transforming UMAP on </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99</span><span style=\"color: #000080; text-decoration-color: #000080\"> samples</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Transforming UMAP on \u001b[0m\u001b[1;36m99\u001b[0m\u001b[34m samples\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: Computed </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #008000; text-decoration-color: #008000\">-d embedding in columns </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'embed_2d_0'</span><span style=\"color: #008000; text-decoration-color: #008000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'embed_2d_1'</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: Computed \u001b[0m\u001b[1;36m2\u001b[0m\u001b[32m-d embedding in columns \u001b[0m\u001b[1;32m[\u001b[0m\u001b[32m'embed_2d_0'\u001b[0m\u001b[32m, \u001b[0m\u001b[32m'embed_2d_1'\u001b[0m\u001b[1;32m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# any kwargs will be passed onto the corresponding reduction\n",
    "# for umap: https://umap-learn.readthedocs.io/en/latest/parameters.html\n",
    "# for ivis: https://bering-ivis.readthedocs.io/en/latest/api.html\n",
    "reducer = dataset.compute_nd_embedding(vectorizer, \"umap\", dimension=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cca2e1f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## **Recipe-Specific Ingredient**\n",
    "\n",
    "Each recipe has different functionalities and potentially different signature.\n",
    "\n",
    "To utilize active learning, we need to specify how to get a model in the loop.\n",
    "\n",
    "`hover` considers the `vectorizer` as a \"frozen\" embedding and follows up with a neural network, which infers its own dimensionality from the vectorizer and the output classes.\n",
    "\n",
    "-   This architecture named [`VectorNet`](../../reference/core-neural/#hover.core.neural.VectorNet) is the (default) basis of active learning in `hover`.\n",
    "\n",
    "-   <details open><summary>Custom models</summary>\n",
    "    It is possible to use a model other than `VectorNet` or its subclass.\n",
    "\n",
    "    You will need to implement the following methods with the same signatures as `VectorNet`:\n",
    "\n",
    "    -   [`train`](../../reference/core-neural/#hover.core.neural.VectorNet.train)\n",
    "    -   [`save`](../../reference/core-neural/#hover.core.neural.VectorNet.save)\n",
    "    -   [`predict_proba`](../../reference/core-neural/#hover.core.neural.VectorNet.predict_proba)\n",
    "    -   [`prepare_loader`](../../reference/core-neural/#hover.core.neural.VectorNet.prepare_loader)\n",
    "    -   [`manifold_trajectory`](../../reference/core-neural/#hover.core.neural.VectorNet.manifold_trajectory)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09ef524f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T01:25:25.194325Z",
     "iopub.status.busy": "2024-04-02T01:25:25.193739Z",
     "iopub.status.idle": "2024-04-02T01:25:25.682538Z",
     "shell.execute_reply": "2024-04-02T01:25:25.681846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ VectorNet: reset neural net: in </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span><span style=\"color: #008000; text-decoration-color: #008000\"> out </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ VectorNet: reset neural net: in \u001b[0m\u001b[1;36m300\u001b[0m\u001b[32m out \u001b[0m\u001b[1;36m20\u001b[0m\u001b[32m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ VectorNet: finished setting up bokeh elements.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ VectorNet: finished setting up bokeh elements.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.9482014e-04 2.0834817e-02 8.7648444e-03 3.9433469e-03 2.2791356e-03\n",
      " 4.4917533e-01 8.5354820e-02 2.3956878e-02 8.3122902e-02 7.0444094e-03\n",
      " 1.2922891e-02 1.1891698e-04 5.0107744e-03 1.2934785e-03 9.0202829e-04\n",
      " 1.4671599e-02 5.1190672e-03 7.4782777e-03 1.3093157e-01 1.3618010e-01]\n",
      "[[8.9482014e-04 2.0834817e-02 8.7648444e-03 3.9433469e-03 2.2791356e-03\n",
      "  4.4917533e-01 8.5354820e-02 2.3956878e-02 8.3122902e-02 7.0444094e-03\n",
      "  1.2922891e-02 1.1891698e-04 5.0107744e-03 1.2934785e-03 9.0202829e-04\n",
      "  1.4671599e-02 5.1190672e-03 7.4782777e-03 1.3093157e-01 1.3618010e-01]]\n"
     ]
    }
   ],
   "source": [
    "from hover.core.neural import VectorNet\n",
    "from hover.utils.common_nn import LogisticRegression\n",
    "\n",
    "# Create a model with vectorizer-NN architecture.\n",
    "# model.pt will point to a PyTorch state dict (to be created)\n",
    "# the label classes in the dataset can change, and vecnet can adjust to that\n",
    "vecnet = VectorNet(vectorizer, LogisticRegression, \"model.pt\", dataset.classes)\n",
    "\n",
    "# predict_proba accepts individual strings or list\n",
    "# text -> vector -> class probabilities\n",
    "# if no classes right now, will see an empty list\n",
    "print(vecnet.predict_proba(text))\n",
    "print(vecnet.predict_proba([text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53248d6",
   "metadata": {},
   "source": [
    "Note how the callback dynamically takes `dataset.classes`, which means the model architecture will adapt when we add classes during annotation.\n",
    "\n",
    "## :sparkles: **Apply Labels**\n",
    "\n",
    "Now we invoke the `active_learning` recipe.\n",
    "\n",
    "-   <details open><summary>Tips: how recipes work programmatically</summary>\n",
    "    In general, a `recipe` is a function taking a `SupervisableDataset` and other arguments based on its functionality.\n",
    "\n",
    "    Here are a few common recipes:\n",
    "\n",
    "    === \"active_learning\"\n",
    "\n",
    "        ::: hover.recipes.experimental.active_learning\n",
    "            rendering:\n",
    "              show_root_heading: false\n",
    "              show_root_toc_entry: false\n",
    "\n",
    "    === \"simple_annotator\"\n",
    "\n",
    "        ::: hover.recipes.stable.simple_annotator\n",
    "            rendering:\n",
    "              show_root_heading: false\n",
    "              show_root_toc_entry: false\n",
    "\n",
    "    === \"linked_annotator\"\n",
    "\n",
    "        ::: hover.recipes.stable.linked_annotator\n",
    "            rendering:\n",
    "              show_root_heading: false\n",
    "              show_root_toc_entry: false\n",
    "\n",
    "    The recipe returns a `handle` function which `bokeh` can use to visualize an annotation interface in multiple settings.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24ce6819",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T01:25:25.685741Z",
     "iopub.status.busy": "2024-04-02T01:25:25.685077Z",
     "iopub.status.idle": "2024-04-02T01:25:25.759454Z",
     "shell.execute_reply": "2024-04-02T01:25:25.758838Z"
    }
   },
   "outputs": [],
   "source": [
    "from hover.recipes.experimental import active_learning\n",
    "\n",
    "interactive_plot = active_learning(dataset, vecnet)\n",
    "\n",
    "# ---------- NOTEBOOK MODE: for your actual Jupyter environment ---------\n",
    "# this code will render the entire plot in Jupyter\n",
    "# from bokeh.io import show, output_notebook\n",
    "# output_notebook()\n",
    "# show(interactive_plot, notebook_url='https://localhost:8888')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3ddd55",
   "metadata": {},
   "source": [
    "-   <details open><summary>Tips: annotation interface with multiple plots</summary>\n",
    "    <details open><summary>Video guide: leveraging linked selection</summary>\n",
    "        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/TIwBlCH9YHw\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Video guide: active learning</summary>\n",
    "        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hRIn3r7ovQ8\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Text guide: active learning</summary>\n",
    "        Inspecting model predictions allows us to\n",
    "\n",
    "        -   get an idea of how the current set of annotations will likely teach the model.\n",
    "        -   locate the most valuable samples for further annotation.\n",
    "    </details>\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
