{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a68f267",
   "metadata": {},
   "source": [
    "> The most common usage of `hover` is through built-in `recipe`s like in the quickstart.\n",
    ">\n",
    "> :ferris_wheel: Let's explore another `recipe` -- an active learning example.\n",
    "\n",
    "-   <details open><summary>Dependencies for {== local environments ==}</summary>\n",
    "    When you run the code locally, you may need to install additional packages.\n",
    "\n",
    "    To run the text embedding code on this page, you need:\n",
    "```shell\n",
    "    pip install spacy\n",
    "    python -m spacy download en_core_web_md\n",
    "```\n",
    "\n",
    "    To render `bokeh` plots in Jupyter, you need:\n",
    "```shell\n",
    "    pip install jupyter_bokeh\n",
    "```\n",
    "\n",
    "    If you are using JupyterLab older than 3.0, use this instead ([reference](https://pypi.org/project/jupyter-bokeh/)):\n",
    "```shell\n",
    "    jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "    jupyter labextension install @bokeh/jupyter_bokeh\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "## **Fundamentals**\n",
    "\n",
    "Hover `recipe`s are functions that take a `SupervisableDataset` and return an annotation interface.\n",
    "\n",
    "The `SupervisableDataset` is assumed to have some data and embeddings.\n",
    "\n",
    "## **Recap: Data & Embeddings**\n",
    "\n",
    "Let's preprare a dataset with embeddings. This is almost the same as in the [quickstart](../t0-quickstart/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a251da6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T02:51:05.373133Z",
     "iopub.status.busy": "2022-09-06T02:51:05.372802Z",
     "iopub.status.idle": "2022-09-06T02:51:07.882606Z",
     "shell.execute_reply": "2022-09-06T02:51:07.881661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: Initializing</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: Initializing\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: Deduplicating</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: Deduplicating\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: --subset raw rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">364</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: --subset raw rows: \u001b[0m\u001b[1;36m400\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m364\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: --subset train rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">380</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: --subset train rows: \u001b[0m\u001b[1;36m400\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m380\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: --subset dev rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: --subset dev rows: \u001b[0m\u001b[1;36m100\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m99\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: --subset test rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: --subset test rows: \u001b[0m\u001b[1;36m100\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m100\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">游릭 SupervisableTextDataset: Set up label encoder/decoder with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span><span style=\"color: #008000; text-decoration-color: #008000\"> classes.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m游릭 SupervisableTextDataset: Set up label encoder/decoder with \u001b[0m\u001b[1;36m20\u001b[0m\u001b[32m classes.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">游릭 SupervisableTextDataset: Population updater: latest population with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span><span style=\"color: #008000; text-decoration-color: #008000\"> classes.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m游릭 SupervisableTextDataset: Population updater: latest population with \u001b[0m\u001b[1;36m20\u001b[0m\u001b[32m classes.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">游릭 SupervisableTextDataset: SupervisableTextDataset: finished initialization.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m游릭 SupervisableTextDataset: SupervisableTextDataset: finished initialization.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hover.core.dataset import SupervisableTextDataset\n",
    "import pandas as pd\n",
    "\n",
    "raw_csv_path = \"https://raw.githubusercontent.com/phurwicz/hover-gallery/main/0.5.0/20_newsgroups_raw.csv\"\n",
    "train_csv_path = \"https://raw.githubusercontent.com/phurwicz/hover-gallery/main/0.5.0/20_newsgroups_train.csv\"\n",
    "\n",
    "# for fast, low-memory demonstration purpose, sample the data\n",
    "df_raw = pd.read_csv(raw_csv_path).sample(400)\n",
    "df_raw[\"SUBSET\"] = \"raw\"\n",
    "df_train = pd.read_csv(train_csv_path).sample(400)\n",
    "df_train[\"SUBSET\"] = \"train\"\n",
    "df_dev = pd.read_csv(train_csv_path).sample(100)\n",
    "df_dev[\"SUBSET\"] = \"dev\"\n",
    "df_test = pd.read_csv(train_csv_path).sample(100)\n",
    "df_test[\"SUBSET\"] = \"test\"\n",
    "\n",
    "# build overall dataframe and ensure feature type\n",
    "df = pd.concat([df_raw, df_train, df_dev, df_test])\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "\n",
    "# this class stores the dataset throught the labeling process\n",
    "dataset = SupervisableTextDataset.from_pandas(df, feature_key=\"text\", label_key=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899b7c62",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91821426",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T02:51:07.887415Z",
     "iopub.status.busy": "2022-09-06T02:51:07.886869Z",
     "iopub.status.idle": "2022-09-06T02:51:11.262250Z",
     "shell.execute_reply": "2022-09-06T02:51:11.261373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: }>}So stop dodging the question.  What is hypocritical about my }>}criticizing bad arguments, given that I do this both when I agree }>}with the conclusion and when I disagree with the conclusion?   }> }>You are the one who has claimed to possess the fruits of precognition, }>telepathy, and telempathy.  Divine it yourself. } }Another dodge.  Oh well.  I'm no match for your amazing repertoire }of red herrings and smoke screens.   } }You asked for an apology.  I'm not going to apologize for pointing out }that your straw-man argument was a straw-man argument.  Nor for saying }that your list of \"bible contradictions\" shows such low standards of }scholarship that it should be an embarrassment to anti-inerrantists, }just as Josh McDowell should be an embarrassment to the fundies.  Nor }for objecting various times to your taking quotes out of context.  Nor }for pointing out that \"they do it too\" is not an excuse. Nor for calling }your red herrings and smoke screens what they are.  How about the following inaccurate, unsubstantiated accusations: In 8257@blue.cis.pitt.edu  - but no \"threat\" produced   - display of telepathy  - in spite of no \"threat\" produced, nor forecast ever happening (precognition?)  - in spite of claimed threat never being given  - in spite of it never happening.  telepathy or precognition?  - unsubstantiated and untrue.  more telepathy?  Or maybe telempathy?  - unsubstantiated again.  Seems to be a habit...  Having more trouble with reality, it appears.  Why get bothered with the facts when you appear to have the products of paranatural divination methods? \n",
      "Vector shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "from functools import lru_cache\n",
    "\n",
    "# use your preferred embedding for the task\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# raw data (str in this case) -> np.array\n",
    "@lru_cache(maxsize=int(1e+4))\n",
    "def vectorizer(text):\n",
    "    clean_text = re.sub(r\"[\\s]+\", r\" \", str(text))\n",
    "    return nlp(clean_text, disable=nlp.pipe_names).vector\n",
    "\n",
    "text = dataset.dfs[\"raw\"].loc[0, \"text\"]\n",
    "vec = vectorizer(text)\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Vector shape: {vec.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641dd720",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef895e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T02:51:11.266481Z",
     "iopub.status.busy": "2022-09-06T02:51:11.266062Z",
     "iopub.status.idle": "2022-09-06T02:51:42.479899Z",
     "shell.execute_reply": "2022-09-06T02:51:42.478681Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 943/943 [00:03<00:00, 306.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: Fit-transforming UMAP on </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">843</span><span style=\"color: #000080; text-decoration-color: #000080\"> samples</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: Fit-transforming UMAP on \u001b[0m\u001b[1;36m843\u001b[0m\u001b[34m samples\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">游댯 SupervisableTextDataset: Transforming UMAP on </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"color: #000080; text-decoration-color: #000080\"> samples</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m游댯 SupervisableTextDataset: Transforming UMAP on \u001b[0m\u001b[1;36m100\u001b[0m\u001b[34m samples\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">游릭 SupervisableTextDataset: Computed </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #008000; text-decoration-color: #008000\">-d embedding in columns </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'embed_2d_0'</span><span style=\"color: #008000; text-decoration-color: #008000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'embed_2d_1'</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m游릭 SupervisableTextDataset: Computed \u001b[0m\u001b[1;36m2\u001b[0m\u001b[32m-d embedding in columns \u001b[0m\u001b[1;32m[\u001b[0m\u001b[32m'embed_2d_0'\u001b[0m\u001b[32m, \u001b[0m\u001b[32m'embed_2d_1'\u001b[0m\u001b[1;32m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# any kwargs will be passed onto the corresponding reduction\n",
    "# for umap: https://umap-learn.readthedocs.io/en/latest/parameters.html\n",
    "# for ivis: https://bering-ivis.readthedocs.io/en/latest/api.html\n",
    "reducer = dataset.compute_nd_embedding(vectorizer, \"umap\", dimension=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a56953",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## **Recipe-Specific Ingredient**\n",
    "\n",
    "Each recipe has different functionalities and potentially different signature.\n",
    "\n",
    "To utilize active learning, we need to specify how to get a model in the loop.\n",
    "\n",
    "`hover` considers the `vectorizer` as a \"frozen\" embedding and follows up with a neural network, which infers its own dimensionality from the vectorizer and the output classes.\n",
    "\n",
    "-   This architecture named [`VectorNet`](../../reference/core-neural/#hover.core.neural.VectorNet) is the (default) basis of active learning in `hover`.\n",
    "\n",
    "-   <details open><summary>Custom models</summary>\n",
    "    It is possible to use a model other than `VectorNet` or its subclass.\n",
    "\n",
    "    You will need to implement the following methods with the same signatures as `VectorNet`:\n",
    "\n",
    "    -   [`train`](../../reference/core-neural/#hover.core.neural.VectorNet.train)\n",
    "    -   [`save`](../../reference/core-neural/#hover.core.neural.VectorNet.save)\n",
    "    -   [`predict_proba`](../../reference/core-neural/#hover.core.neural.VectorNet.predict_proba)\n",
    "    -   [`prepare_loader`](../../reference/core-neural/#hover.core.neural.VectorNet.prepare_loader)\n",
    "    -   [`manifold_trajectory`](../../reference/core-neural/#hover.core.neural.VectorNet.manifold_trajectory)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "977824c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T02:51:42.484513Z",
     "iopub.status.busy": "2022-09-06T02:51:42.484216Z",
     "iopub.status.idle": "2022-09-06T02:51:42.506176Z",
     "shell.execute_reply": "2022-09-06T02:51:42.503693Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">游릭 VectorNet: reset neural net: in </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span><span style=\"color: #008000; text-decoration-color: #008000\"> out </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m游릭 VectorNet: reset neural net: in \u001b[0m\u001b[1;36m300\u001b[0m\u001b[32m out \u001b[0m\u001b[1;36m20\u001b[0m\u001b[32m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.9448170e-03 1.1683714e-02 1.2149203e-02 5.2206564e-01 6.4165366e-04\n",
      " 1.4752968e-02 6.1245449e-03 3.0754615e-02 1.7415592e-02 1.4024959e-02\n",
      " 2.0188045e-04 1.3352622e-02 5.6514842e-04 2.3103708e-01 7.1749888e-02\n",
      " 1.9365769e-03 1.2635428e-04 7.8942068e-03 8.4685888e-03 3.1109951e-02]\n",
      "[[3.9448170e-03 1.1683714e-02 1.2149203e-02 5.2206564e-01 6.4165366e-04\n",
      "  1.4752968e-02 6.1245449e-03 3.0754615e-02 1.7415592e-02 1.4024959e-02\n",
      "  2.0188045e-04 1.3352622e-02 5.6514842e-04 2.3103708e-01 7.1749888e-02\n",
      "  1.9365769e-03 1.2635428e-04 7.8942068e-03 8.4685888e-03 3.1109951e-02]]\n"
     ]
    }
   ],
   "source": [
    "from hover.core.neural import VectorNet\n",
    "from hover.utils.common_nn import LogisticRegression\n",
    "\n",
    "# Create a model with vectorizer-NN architecture.\n",
    "# model.pt will point to a PyTorch state dict (to be created)\n",
    "# the label classes in the dataset can change, and vecnet can adjust to that\n",
    "vecnet = VectorNet(vectorizer, LogisticRegression, \"model.pt\", dataset.classes)\n",
    "\n",
    "# predict_proba accepts individual strings or list\n",
    "# text -> vector -> class probabilities\n",
    "# if no classes right now, will see an empty list\n",
    "print(vecnet.predict_proba(text))\n",
    "print(vecnet.predict_proba([text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f7b0d",
   "metadata": {},
   "source": [
    "Note how the callback dynamically takes `dataset.classes`, which means the model architecture will adapt when we add classes during annotation.\n",
    "\n",
    "## :sparkles: **Apply Labels**\n",
    "\n",
    "Now we invoke the `active_learning` recipe.\n",
    "\n",
    "-   <details open><summary>Tips: how recipes work programmatically</summary>\n",
    "    In general, a `recipe` is a function taking a `SupervisableDataset` and other arguments based on its functionality.\n",
    "\n",
    "    Here are a few common recipes:\n",
    "\n",
    "    === \"active_learning\"\n",
    "\n",
    "        ::: hover.recipes.experimental.active_learning\n",
    "            rendering:\n",
    "              show_root_heading: false\n",
    "              show_root_toc_entry: false\n",
    "\n",
    "    === \"simple_annotator\"\n",
    "\n",
    "        ::: hover.recipes.stable.simple_annotator\n",
    "            rendering:\n",
    "              show_root_heading: false\n",
    "              show_root_toc_entry: false\n",
    "\n",
    "    === \"linked_annotator\"\n",
    "\n",
    "        ::: hover.recipes.stable.linked_annotator\n",
    "            rendering:\n",
    "              show_root_heading: false\n",
    "              show_root_toc_entry: false\n",
    "\n",
    "    The recipe returns a `handle` function which `bokeh` can use to visualize an annotation interface in multiple settings.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cda6d96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T02:51:42.511553Z",
     "iopub.status.busy": "2022-09-06T02:51:42.511242Z",
     "iopub.status.idle": "2022-09-06T02:51:42.592931Z",
     "shell.execute_reply": "2022-09-06T02:51:42.591919Z"
    }
   },
   "outputs": [],
   "source": [
    "from hover.recipes.experimental import active_learning\n",
    "\n",
    "interactive_plot = active_learning(dataset, vecnet)\n",
    "\n",
    "# ---------- NOTEBOOK MODE: for your actual Jupyter environment ---------\n",
    "# this code will render the entire plot in Jupyter\n",
    "# from bokeh.io import show, output_notebook\n",
    "# output_notebook()\n",
    "# show(interactive_plot, notebook_url='https://localhost:8888')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b493e29a",
   "metadata": {},
   "source": [
    "-   <details open><summary>Tips: annotation interface with multiple plots</summary>\n",
    "    <details open><summary>Video guide: leveraging linked selection</summary>\n",
    "        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/TIwBlCH9YHw\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Video guide: active learning</summary>\n",
    "        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hRIn3r7ovQ8\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Text guide: active learning</summary>\n",
    "        Inspecting model predictions allows us to\n",
    "\n",
    "        -   get an idea of how the current set of annotations will likely teach the model.\n",
    "        -   locate the most valuable samples for further annotation.\n",
    "    </details>\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
