
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Hover and label data rapidly.">
      
      
      
        <link rel="canonical" href="https://phurwicz.github.io/hover/pages/reference/core-neural/">
      
      <link rel="icon" href="../../../images/favicon.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-8.1.9">
    
    
      
        <title>hover.core.neural - Hover</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.2b4465f4.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.e6a45f82.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  


  <script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-211167044-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){var e;this.value&&(e=document.location.pathname,ga("send","pageview",e+"?q="+this.value))}),"undefined"!=typeof location$&&location$.subscribe(function(e){ga("send","pageview",e.pathname)})})</script>
  <script async src="https://www.google-analytics.com/analytics.js"></script>


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#hover.core.neural" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Hover" class="md-header__button md-logo" aria-label="Hover" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9 7v10h2v-4h2v4h2V7h-2v4h-2V7H9M5 3h14a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Hover
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              hover.core.neural
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/phurwicz/hover.git/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    phurwicz/hover
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../../.." class="md-tabs__link">
      Home
    </a>
  </li>

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../tutorial/t0-quickstart/" class="md-tabs__link">
        Tutorial
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../guides/g0-datatype-image/" class="md-tabs__link">
        Guides
      </a>
    </li>
  

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="../recipes/" class="md-tabs__link md-tabs__link--active">
        API Reference
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Hover" class="md-nav__button md-logo" aria-label="Hover" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9 7v10h2v-4h2v4h2V7h-2v4h-2V7H9M5 3h14a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2z"/></svg>

    </a>
    Hover
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/phurwicz/hover.git/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    phurwicz/hover
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" data-md-state="indeterminate" type="checkbox" id="__nav_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Tutorial
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Tutorial" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Tutorial
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorial/t0-quickstart/" class="md-nav__link">
        Quickstart
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorial/t1-active-learning/" class="md-nav__link">
        Using Recipes
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorial/t2-bokeh-app/" class="md-nav__link">
        Server Options
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorial/t3-dataset-population-selection/" class="md-nav__link">
        Dataset Mechanisms
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorial/t4-annotator-dataset-interaction/" class="md-nav__link">
        Annotator & Plot Tools
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorial/t5-finder-filter/" class="md-nav__link">
        Finder & Selection Filter
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorial/t6-softlabel-joint-filter/" class="md-nav__link">
        Soft Label & Joint Filters
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorial/t7-snorkel-improvise-rules/" class="md-nav__link">
        Custom Labeling Functions
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" data-md-state="indeterminate" type="checkbox" id="__nav_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Guides
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Guides" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Guides
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/g0-datatype-image/" class="md-nav__link">
        Image Data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/g1-datatype-audio/" class="md-nav__link">
        Audio Data
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          API Reference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="API Reference" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          API Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../recipes/" class="md-nav__link">
        hover.recipes
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2" type="checkbox" id="__nav_4_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2">
          hover.core
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="hover.core" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_2">
          <span class="md-nav__icon md-icon"></span>
          hover.core
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../core-dataset/" class="md-nav__link">
        hover.core.dataset
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2_2" data-md-state="indeterminate" type="checkbox" id="__nav_4_2_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2_2">
          hover.core.explorer
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="hover.core.explorer" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_2_2">
          <span class="md-nav__icon md-icon"></span>
          hover.core.explorer
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../core-explorer-base/" class="md-nav__link">
        .base
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../core-explorer-feature/" class="md-nav__link">
        .feature
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../core-explorer-functionality/" class="md-nav__link">
        .functionality
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../core-explorer-specialization/" class="md-nav__link">
        .specialization
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          hover.core.neural
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        hover.core.neural
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#hover.core.neural" class="md-nav__link">
    hover.core.neural
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hover.core.neural.BaseVectorNet" class="md-nav__link">
    BaseVectorNet
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hover.core.neural.VectorNet" class="md-nav__link">
    VectorNet
  </a>
  
    <nav class="md-nav" aria-label="VectorNet">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hover.core.neural.VectorNet.DEFAULT_OPTIM_CLS" class="md-nav__link">
    DEFAULT_OPTIM_CLS
  </a>
  
    <nav class="md-nav" aria-label="DEFAULT_OPTIM_CLS">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hover.core.neural.VectorNet.DEFAULT_OPTIM_CLS.step" class="md-nav__link">
    step()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hover.core.neural.VectorNet.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hover.core.neural.VectorNet.adjust_optimizer_params" class="md-nav__link">
    adjust_optimizer_params()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hover.core.neural.VectorNet.auto_adjust_setup" class="md-nav__link">
    auto_adjust_setup()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hover.core.neural.VectorNet.evaluate" class="md-nav__link">
    evaluate()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hover.core.neural.VectorNet.from_module" class="md-nav__link">
    from_module()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hover.core.neural.VectorNet.load" class="md-nav__link">
    load()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hover.core.neural.VectorNet.manifold_trajectory" class="md-nav__link">
    manifold_trajectory()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hover.core.neural.VectorNet.predict_proba" class="md-nav__link">
    predict_proba()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hover.core.neural.VectorNet.prepare_loader" class="md-nav__link">
    prepare_loader()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hover.core.neural.VectorNet.save" class="md-nav__link">
    save()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hover.core.neural.VectorNet.setup_label_conversion" class="md-nav__link">
    setup_label_conversion()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hover.core.neural.VectorNet.setup_nn" class="md-nav__link">
    setup_nn()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hover.core.neural.VectorNet.train" class="md-nav__link">
    train()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hover.core.neural.VectorNet.train_batch" class="md-nav__link">
    train_batch()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hover.core.neural.VectorNet.train_epoch" class="md-nav__link">
    train_epoch()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hover.core.neural.VectorNet.view" class="md-nav__link">
    view()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../core-representation/" class="md-nav__link">
        hover.core.representation
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3" data-md-state="indeterminate" type="checkbox" id="__nav_4_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3">
          hover.utils
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="hover.utils" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_3">
          <span class="md-nav__icon md-icon"></span>
          hover.utils
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../utils-bokeh_helper/" class="md-nav__link">
        hover.utils.bokeh_helper
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../utils-snorkel_helper/" class="md-nav__link">
        hover.utils.snorkel_helper
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
<a href="https://github.com/phurwicz/hover.git/edit/master/docs/pages/reference/core-neural.md" title="Edit this page" class="md-content__button md-icon">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
</a>


  <h1>hover.core.neural</h1>

<ul>
<li>
<div class="mkdocstrings">

  <div class="doc doc-object doc-module">

<a id="hover.core.neural"></a>
    <div class="doc doc-contents first">

      <details class="note" open="open">
<summary>Neural network components.</summary>
<p><code>torch</code>-based template classes for implementing neural nets that work the most smoothly with <code>hover</code>.</p>
</details>



  <div class="doc doc-children">







  <div class="doc doc-object doc-class">



<h2 id="hover.core.neural.BaseVectorNet" class="doc doc-heading">
        <code>
BaseVectorNet            (<span title="hover.core.Loggable">Loggable</span>)
        </code>



</h2>

    <div class="doc doc-contents ">

      <details class="note" open="open">
<summary>Abstract transfer learning model defining common signatures.</summary>
<p>Intended to define crucial interactions with built-in recipes like <code>hover.recipes.active_learning()</code>.</p>
</details>

        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">BaseVectorNet</span><span class="p">(</span><span class="n">Loggable</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ???+ note &quot;Abstract transfer learning model defining common signatures.&quot;</span>

<span class="sd">        Intended to define crucial interactions with built-in recipes like `hover.recipes.active_learning()`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inps</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">manifold_trajectory</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">inps</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;umap&quot;</span><span class="p">,</span> <span class="n">reducer_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">spline_kwargs</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
        <span class="k">pass</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">prepare_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">dev_loader</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">















  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 id="hover.core.neural.VectorNet" class="doc doc-heading">
        <code>
VectorNet            (<a title="hover.core.neural.BaseVectorNet" href="#hover.core.neural.BaseVectorNet">BaseVectorNet</a>)
        </code>



</h2>

    <div class="doc doc-contents ">

      <details class="note" open="open">
<summary>Simple transfer learning model: a user-supplied vectorizer followed by a neural net.</summary>
<p>This is a parent class whose children may use different training schemes.</p>
<p>Coupled with:</p>
<ul>
<li><code>hover.utils.torch_helper.VectorDataset</code></li>
</ul>
</details>

        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">VectorNet</span><span class="p">(</span><span class="n">BaseVectorNet</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ???+ note &quot;Simple transfer learning model: a user-supplied vectorizer followed by a neural net.&quot;</span>
<span class="sd">        This is a parent class whose children may use different training schemes.</span>

<span class="sd">        Coupled with:</span>

<span class="sd">        -   `hover.utils.torch_helper.VectorDataset`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">DEFAULT_OPTIM_CLS</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span>
    <span class="n">DEFAULT_OPTIM_LOGLR</span> <span class="o">=</span> <span class="mf">2.0</span>
    <span class="n">DEFAULT_OPTIM_KWARGS</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="o">**</span><span class="n">DEFAULT_OPTIM_LOGLR</span><span class="p">,</span> <span class="s2">&quot;betas&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)}</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">vectorizer</span><span class="p">,</span>
        <span class="n">architecture</span><span class="p">,</span>
        <span class="n">state_dict_path</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">,</span>
        <span class="n">backup_state_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">optimizer_cls</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">optimizer_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">example_input</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ???+ note &quot;Create the `VectorNet`, loading parameters if available.&quot;</span>

<span class="sd">            | Param             | Type       | Description                          |</span>
<span class="sd">            | :---------------- | :--------- | :----------------------------------- |</span>
<span class="sd">            | `vectorizer`      | `callable` | the feature -&gt; vector function       |</span>
<span class="sd">            | `architecture`    | `class`    | a `torch.nn.Module` child class      |</span>
<span class="sd">            | `state_dict_path` | `str`      | path to a (could-be-empty) `torch` state dict |</span>
<span class="sd">            | `labels`          | `list`     | list of `str` classification labels  |</span>
<span class="sd">            | `backup_state_dict` | `bool`   | whether to backup the loaded state dict |</span>
<span class="sd">            | `optimizer_cls`   | `subclass of torch.optim.Optimizer` | pytorch optimizer class |</span>
<span class="sd">            | `optimizer_kwargs`  | `dict`   | pytorch optimizer kwargs             |</span>
<span class="sd">            | `verbose`         | `int`      | logging verbosity level              |</span>
<span class="sd">            | `example_input`   | any        | example input to the vectorizer      |</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">verbose</span><span class="p">,</span> <span class="nb">int</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Expected verbose as int, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">verbose</span><span class="p">)</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">verbose</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">vectorizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">example_input</span> <span class="o">=</span> <span class="n">example_input</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span> <span class="o">=</span> <span class="n">architecture</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_label_conversion</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dynamic_params</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># set a path to store updated parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nn_update_path</span> <span class="o">=</span> <span class="n">state_dict_path</span>

        <span class="k">if</span> <span class="n">backup_state_dict</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">state_dict_path</span><span class="p">):</span>
            <span class="n">state_dict_backup_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">state_dict_path</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">current_time</span><span class="p">(</span><span class="s1">&#39;%Y%m</span><span class="si">%d</span><span class="s1">%H%M%S&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">copyfile</span><span class="p">(</span><span class="n">state_dict_path</span><span class="p">,</span> <span class="n">state_dict_backup_path</span><span class="p">)</span>

        <span class="c1"># initialize an optimizer object and a dict to hold dynamic parameters</span>
        <span class="n">optimizer_cls</span> <span class="o">=</span> <span class="n">optimizer_cls</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">DEFAULT_OPTIM_CLS</span>
        <span class="n">optimizer_kwargs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">optimizer_kwargs</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">DEFAULT_OPTIM_KWARGS</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="k">def</span> <span class="nf">callback_reset_nn_optimizer</span><span class="p">():</span>
            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Callback function which has access to optimizer init settings.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nn_optimizer</span> <span class="o">=</span> <span class="n">optimizer_cls</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">nn_optimizer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Expected an optimizer, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn_optimizer</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dynamic_params</span><span class="p">[</span><span class="s2">&quot;optimizer&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimizer_kwargs</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_callback_reset_nn_optimizer</span> <span class="o">=</span> <span class="n">callback_reset_nn_optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_nn</span><span class="p">(</span><span class="n">use_existing_state_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_widgets</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">auto_adjust_setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">auto_skip</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ???+ note &quot;Auto-(re)create label encoder/decoder and neural net.&quot;</span>

<span class="sd">            Intended to be called in and out of the constructor.</span>

<span class="sd">            | Param             | Type       | Description                          |</span>
<span class="sd">            | :---------------- | :--------- | :----------------------------------- |</span>
<span class="sd">            | `labels`          | `list`     | list of `str` classification labels  |</span>
<span class="sd">            | `auto_skip`       | `bool`     | skip when labels did not change      |</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># sanity check and skip</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="nb">list</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Expected a list of labels, got </span><span class="si">{</span><span class="n">labels</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="c1"># if the sequence of labels matches label encoder exactly, skip</span>
        <span class="n">label_match_flag</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">==</span> <span class="nb">sorted</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">auto_skip</span> <span class="ow">and</span> <span class="n">label_match_flag</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">setup_label_conversion</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_nn</span><span class="p">(</span><span class="n">use_existing_state_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_good</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;adjusted to new list of labels: </span><span class="si">{</span><span class="n">labels</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setup_label_conversion</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ???+ note &quot;Set up label encoder/decoder and number of classes.&quot;</span>

<span class="sd">            | Param             | Type       | Description                          |</span>
<span class="sd">            | :---------------- | :--------- | :----------------------------------- |</span>
<span class="sd">            | `labels`          | `list`     | list of `str` classification labels  |</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">_label</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="p">)}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">_label</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="p">)}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setup_nn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_existing_state_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ???+ note &quot;Set up neural network and optimizers.&quot;</span>

<span class="sd">            Intended to be called in and out of the constructor.</span>

<span class="sd">            -   will try to load parameters from state dict by default</span>
<span class="sd">            -   option to override and discard previous state dict</span>
<span class="sd">                -   often used when the classification targets have changed</span>

<span class="sd">            | Param                     | Type       | Description                          |</span>
<span class="sd">            | :------------------------ | :--------- | :----------------------------------- |</span>
<span class="sd">            | `labels`                  | `list`     | list of `str` classification labels  |</span>
<span class="sd">            | `use_existing_state_dict` | `bool`     | whether to use existing state dict   |</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># set up vectorizer and the neural network with appropriate dimensions</span>
        <span class="n">vec_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">example_input</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">(</span><span class="n">vec_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_callback_reset_nn_optimizer</span><span class="p">()</span>

        <span class="n">state_dict_exists</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn_update_path</span><span class="p">)</span>
        <span class="c1"># if state dict exists, load it (when consistent) or overwrite</span>
        <span class="k">if</span> <span class="n">state_dict_exists</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">use_existing_state_dict</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn_update_path</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn_update_path</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_good</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;reset neural net: in </span><span class="si">{</span><span class="n">vec_dim</span><span class="si">}</span><span class="s2"> out </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">load_path</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ???+ note &quot;Load neural net parameters if possible.&quot;</span>

<span class="sd">            Can be directed to a custom state dict.</span>

<span class="sd">            | Param       | Type       | Description                  |</span>
<span class="sd">            | :---------- | :--------- | :--------------------------- |</span>
<span class="sd">            | `load_path` | `str`      | path to a `torch` state dict |</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">load_path</span> <span class="o">=</span> <span class="n">load_path</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_update_path</span>
        <span class="c1"># if the architecture cannot match the state dict, skip the load and warn</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">load_path</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;loaded state dict </span><span class="si">{</span><span class="n">load_path</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;load VectorNet state path failed with </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_module</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">model_module</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ???+ note &quot;Create a VectorNet model from a loadable module.&quot;</span>

<span class="sd">            | Param          | Type       | Description                          |</span>
<span class="sd">            | :------------- | :--------- | :----------------------------------- |</span>
<span class="sd">            | `model_module` | `module` or `str` | (path to) a local Python workspace module which contains a get_vectorizer() callable, get_architecture() callable, and a get_state_dict_path() callable |</span>
<span class="sd">            | `labels`       | `list`     | list of `str` classification labels  |</span>
<span class="sd">            | `**kwargs`     |      | forwarded to `self.__init__()` constructor |</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model_module</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="kn">from</span> <span class="nn">importlib</span> <span class="kn">import</span> <span class="n">import_module</span>

            <span class="n">model_module</span> <span class="o">=</span> <span class="n">import_module</span><span class="p">(</span><span class="n">model_module</span><span class="p">)</span>

        <span class="c1"># Load the model by retrieving the inp-to-vec function, architecture, and state dict</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">model_module</span><span class="o">.</span><span class="n">get_vectorizer</span><span class="p">(),</span>
            <span class="n">model_module</span><span class="o">.</span><span class="n">get_architecture</span><span class="p">(),</span>
            <span class="n">model_module</span><span class="o">.</span><span class="n">get_state_dict_path</span><span class="p">(),</span>
            <span class="n">labels</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">model</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ???+ note &quot;Save the current state dict with authorization to overwrite.&quot;</span>
<span class="sd">            | Param       | Type  | Description                           |</span>
<span class="sd">            | :---------- | :---- | :------------------------------------ |</span>
<span class="sd">            | `save_path` | `str` | option alternative path to state dict |</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">save_path</span> <span class="o">=</span> <span class="n">save_path</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_update_path</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">save_path</span><span class="p">)</span>
        <span class="n">verb</span> <span class="o">=</span> <span class="s2">&quot;overwrote&quot;</span> <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;saved&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">verb</span><span class="si">}</span><span class="s2"> state dict </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_setup_widgets</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ???+ note &quot;Bokeh widgets for changing hyperparameters through user interaction.&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epochs_slider</span> <span class="o">=</span> <span class="n">Slider</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;# epochs&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loglr_slider</span> <span class="o">=</span> <span class="n">Slider</span><span class="p">(</span>
            <span class="n">title</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">,</span>
            <span class="n">start</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
            <span class="n">end</span><span class="o">=</span><span class="mf">7.0</span><span class="p">,</span>
            <span class="n">value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">DEFAULT_OPTIM_LOGLR</span><span class="p">,</span>
            <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
            <span class="nb">format</span><span class="o">=</span><span class="n">FuncTickFormatter</span><span class="p">(</span><span class="n">code</span><span class="o">=</span><span class="s2">&quot;return Math.pow(0.1, tick).toFixed(8)&quot;</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="k">def</span> <span class="nf">update_lr</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">old</span><span class="p">,</span> <span class="n">new</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dynamic_params</span><span class="p">[</span><span class="s2">&quot;optimizer&quot;</span><span class="p">][</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.1</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">loglr_slider</span><span class="o">.</span><span class="n">value</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loglr_slider</span><span class="o">.</span><span class="n">on_change</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="n">update_lr</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_layout_widgets</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ???+ note &quot;Layout of widgets when plotted.&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">bokeh.layouts</span> <span class="kn">import</span> <span class="n">row</span>

        <span class="k">return</span> <span class="n">row</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epochs_slider</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglr_slider</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">view</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ???+ note &quot;Overall layout when plotted.&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layout_widgets</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">adjust_optimizer_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ???+ note &quot;Dynamically change parameters of the neural net optimizer.&quot;</span>

<span class="sd">            - Intended to be polymorphic in child classes and to be called per epoch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">_group</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">_group</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dynamic_params</span><span class="p">[</span><span class="s2">&quot;optimizer&quot;</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inps</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ???+ note &quot;End-to-end single/multi-piece prediction from inp to class probabilities.&quot;</span>
<span class="sd">            | Param  | Type    | Description                          |</span>
<span class="sd">            | :----- | :------ | :----------------------------------- |</span>
<span class="sd">            | `inps` | dynamic | (a list of) input features to vectorize |</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># if the input is a single piece of inp, cast it to a list</span>
        <span class="n">FLAG_SINGLE</span> <span class="o">=</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inps</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">FLAG_SINGLE</span><span class="p">:</span>
            <span class="n">inps</span> <span class="o">=</span> <span class="p">[</span><span class="n">inps</span><span class="p">]</span>

        <span class="c1"># the actual prediction</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">vectors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="p">(</span><span class="n">_inp</span><span class="p">)</span> <span class="k">for</span> <span class="n">_inp</span> <span class="ow">in</span> <span class="n">inps</span><span class="p">]))</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="c1"># inverse-cast if applicable</span>
        <span class="k">if</span> <span class="n">FLAG_SINGLE</span><span class="p">:</span>
            <span class="n">probs</span> <span class="o">=</span> <span class="n">probs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">probs</span>

    <span class="k">def</span> <span class="nf">manifold_trajectory</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">inps</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;umap&quot;</span><span class="p">,</span> <span class="n">reducer_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">spline_kwargs</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ???+ note &quot;Compute a propagation trajectory of the dataset manifold through the neural net.&quot;</span>

<span class="sd">            1. vectorize inps</span>
<span class="sd">            2. forward propagate, keeping intermediates</span>
<span class="sd">            3. fit intermediates to N-D manifolds</span>
<span class="sd">            4. fit manifolds using Procrustes shape analysis</span>
<span class="sd">            5. fit shapes to trajectory splines</span>

<span class="sd">            | Param    | Type    | Description                          |</span>
<span class="sd">            | :------- | :------ | :----------------------------------- |</span>
<span class="sd">            | `inps`   | dynamic | (a list of) input features to vectorize |</span>
<span class="sd">            | `method` | `str`   | reduction method: `&quot;umap&quot;` or `&quot;ivis&quot;`  |</span>
<span class="sd">            | `reducer_kwargs` | | kwargs to forward to dimensionality reduction |</span>
<span class="sd">            | `spline_kwargs` | | kwargs to forward to spline calculation |</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">hover.core.representation.manifold</span> <span class="kn">import</span> <span class="n">LayerwiseManifold</span>
        <span class="kn">from</span> <span class="nn">hover.core.representation.trajectory</span> <span class="kn">import</span> <span class="n">manifold_spline</span>

        <span class="n">reducer_kwargs</span> <span class="o">=</span> <span class="n">reducer_kwargs</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="n">spline_kwargs</span> <span class="o">=</span> <span class="n">spline_kwargs</span> <span class="ow">or</span> <span class="p">{}</span>

        <span class="c1"># step 1 &amp; 2</span>
        <span class="n">vectors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="p">(</span><span class="n">_inp</span><span class="p">)</span> <span class="k">for</span> <span class="n">_inp</span> <span class="ow">in</span> <span class="n">inps</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">intermediates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">eval_per_layer</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="n">intermediates</span> <span class="o">=</span> <span class="p">[</span><span class="n">_tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">_tensor</span> <span class="ow">in</span> <span class="n">intermediates</span><span class="p">]</span>

        <span class="c1"># step 3 &amp; 4</span>
        <span class="n">LM</span> <span class="o">=</span> <span class="n">LayerwiseManifold</span><span class="p">(</span><span class="n">intermediates</span><span class="p">)</span>
        <span class="n">LM</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span> <span class="o">**</span><span class="n">reducer_kwargs</span><span class="p">)</span>
        <span class="n">seq_arr</span><span class="p">,</span> <span class="n">disparities</span> <span class="o">=</span> <span class="n">LM</span><span class="o">.</span><span class="n">procrustes</span><span class="p">()</span>
        <span class="n">seq_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">seq_arr</span><span class="p">)</span>

        <span class="c1"># step 5</span>
        <span class="n">traj_arr</span> <span class="o">=</span> <span class="n">manifold_spline</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">seq_arr</span><span class="p">),</span> <span class="o">**</span><span class="n">spline_kwargs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">traj_arr</span><span class="p">,</span> <span class="n">seq_arr</span><span class="p">,</span> <span class="n">disparities</span>

    <span class="k">def</span> <span class="nf">prepare_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ???+ note &quot;Create dataloader from `SupervisableDataset` with implied vectorizer(s).&quot;</span>

<span class="sd">            | Param      | Type  | Description                |</span>
<span class="sd">            | :--------- | :---- | :------------------------- |</span>
<span class="sd">            | `dataset`  | `hover.core.dataset.SupervisableDataset` | the dataset to load |</span>
<span class="sd">            | `key`      | `str` | &quot;train&quot;, &quot;dev&quot;, or &quot;test&quot;  |</span>
<span class="sd">            | `**kwargs` | | forwarded to `dataset.loader()`  |</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">dataset</span><span class="o">.</span><span class="n">loader</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">dev_loader</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ???+ note &quot;Train the neural network part of the VecNet.&quot;</span>

<span class="sd">            - intended to be coupled with self.train_batch().</span>

<span class="sd">            | Param          | Type         | Description                |</span>
<span class="sd">            | :------------- | :----------- | :------------------------- |</span>
<span class="sd">            | `train_loader` | `torch.utils.data.DataLoader` | train set |</span>
<span class="sd">            | `dev_loader`   | `torch.utils.data.DataLoader` | dev set   |</span>
<span class="sd">            | `epochs`       | `int`        | number of epochs to train  |</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">epochs_slider</span><span class="o">.</span><span class="n">value</span>

        <span class="n">train_info</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">epoch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dynamic_params</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">epoch_idx</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_epoch</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">dev_loader</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">dev_loader</span> <span class="o">=</span> <span class="n">train_loader</span>
            <span class="n">acc</span><span class="p">,</span> <span class="n">conf_mat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">dev_loader</span><span class="p">)</span>
            <span class="n">train_info</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="n">acc</span><span class="p">,</span> <span class="s2">&quot;confusion_matrix&quot;</span><span class="p">:</span> <span class="n">conf_mat</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">train_info</span>

    <span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ???+ note &quot;Train the neural network for one epoch.&quot;</span>

<span class="sd">            - Supports flexible args and kwargs for child classes that may implement self.train() and self.train_batch() differently.</span>

<span class="sd">            | Param          | Type         | Description                |</span>
<span class="sd">            | :------------- | :----------- | :------------------------- |</span>
<span class="sd">            | `train_loader` | `torch.utils.data.DataLoader` | train set |</span>
<span class="sd">            | `*args`        | | arguments to forward to `train_batch`   |</span>
<span class="sd">            | `**kwargs`     | | kwargs to forward to `train_batch`      |</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adjust_optimizer_params</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">loaded_input</span><span class="p">,</span> <span class="n">loaded_output</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dynamic_params</span><span class="p">[</span><span class="s2">&quot;batch&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_idx</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_batch</span><span class="p">(</span><span class="n">loaded_input</span><span class="p">,</span> <span class="n">loaded_output</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loaded_input</span><span class="p">,</span> <span class="n">loaded_output</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ???+ note &quot;Train the neural network for one batch.&quot;</span>

<span class="sd">            | Param           | Type           | Description           |</span>
<span class="sd">            | :-------------- | :------------- | :-------------------- |</span>
<span class="sd">            | `loaded_input`  | `torch.Tensor` | input tensor          |</span>
<span class="sd">            | `loaded_output` | `torch.Tensor` | output tensor         |</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">loaded_input</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">loaded_output</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

        <span class="c1"># compute logits</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">output_tensor</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">nn_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nn_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">log_info</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dynamic_params</span><span class="p">)</span>
            <span class="n">log_info</span><span class="p">[</span><span class="s2">&quot;performance&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;Loss </span><span class="si">{0:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_print</span><span class="p">(</span>
                <span class="s2">&quot;</span><span class="si">{0: &lt;80}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="s2">&quot;Train: Epoch </span><span class="si">{epoch}</span><span class="s2"> Batch </span><span class="si">{batch}</span><span class="s2"> </span><span class="si">{performance}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="o">**</span><span class="n">log_info</span>
                    <span class="p">)</span>
                <span class="p">),</span>
                <span class="n">end</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dev_loader</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ???+ note &quot;Evaluate the VecNet against a dev set.&quot;</span>

<span class="sd">            | Param        | Type         | Description                |</span>
<span class="sd">            | :----------- | :----------- | :------------------------- |</span>
<span class="sd">            | `dev_loader` | `torch.utils.data.DataLoader` | dev set   |</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">true</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">loaded_input</span><span class="p">,</span> <span class="n">loaded_output</span><span class="p">,</span> <span class="n">_idx</span> <span class="ow">in</span> <span class="n">dev_loader</span><span class="p">:</span>
            <span class="n">_input_tensor</span> <span class="o">=</span> <span class="n">loaded_input</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">_output_tensor</span> <span class="o">=</span> <span class="n">loaded_output</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

            <span class="n">_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="p">(</span><span class="n">_input_tensor</span><span class="p">)</span>
            <span class="n">_true_batch</span> <span class="o">=</span> <span class="n">_output_tensor</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">_pred_batch</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">true</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_true_batch</span><span class="p">)</span>
            <span class="n">pred</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_pred_batch</span><span class="p">)</span>
        <span class="n">true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">true</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">classification_accuracy</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
        <span class="n">conf_mat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">log_info</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dynamic_params</span><span class="p">)</span>
            <span class="n">log_info</span><span class="p">[</span><span class="s2">&quot;performance&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;Acc </span><span class="si">{0:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="p">(</span>
                <span class="s2">&quot;</span><span class="si">{0: &lt;80}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="s2">&quot;Eval: Epoch </span><span class="si">{epoch}</span><span class="s2"> </span><span class="si">{performance}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="n">log_info</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">conf_mat</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">









  <div class="doc doc-object doc-class">



<h3 id="hover.core.neural.VectorNet.DEFAULT_OPTIM_CLS" class="doc doc-heading">
        <code>
DEFAULT_OPTIM_CLS            (<span title="torch.optim.optimizer.Optimizer">Optimizer</span>)
        </code>



</h3>

    <div class="doc doc-contents ">

      <p>Implements Adam algorithm.</p>
<p>.. math::
   \begin{aligned}
        &amp;\rule{110mm}{0.4pt}                                                                 \
        &amp;\textbf{input}      : \gamma \text{ (lr)}, \beta_1, \beta_2
            \text{ (betas)},\theta_0 \text{ (params)},f(\theta) \text{ (objective)}          \
        &amp;\hspace{13mm}      \lambda \text{ (weight decay)},  : amsgrad                      \
        &amp;\textbf{initialize} :  m_0 \leftarrow 0 \text{ ( first moment)},
            v_0\leftarrow 0 \text{ (second moment)},: \widehat{v_0}^{max}\leftarrow 0\[-1.ex]
        &amp;\rule{110mm}{0.4pt}                                                                 \
        &amp;\textbf{for} : t=1 : \textbf{to} : \ldots : \textbf{do}                         \
        &amp;\hspace{5mm}g_t           \leftarrow   \nabla_{\theta} f_t (\theta_{t-1})           \
        &amp;\hspace{5mm}\textbf{if} : \lambda \neq 0                                           \
        &amp;\hspace{10mm} g_t \leftarrow g_t + \lambda  \theta_{t-1}                            \
        &amp;\hspace{5mm}m_t           \leftarrow   \beta_1 m_{t-1} + (1 - \beta_1) g_t          \
        &amp;\hspace{5mm}v_t           \leftarrow   \beta_2 v_{t-1} + (1-\beta_2) g^2_t          \
        &amp;\hspace{5mm}\widehat{m_t} \leftarrow   m_t/\big(1-\beta_1^t \big)                   \
        &amp;\hspace{5mm}\widehat{v_t} \leftarrow   v_t/\big(1-\beta_2^t \big)                   \
        &amp;\hspace{5mm}\textbf{if} : amsgrad                                                  \
        &amp;\hspace{10mm}\widehat{v_t}^{max} \leftarrow \mathrm{max}(\widehat{v_t}^{max},
            \widehat{v_t})                                                                   \
        &amp;\hspace{10mm}\theta_t \leftarrow \theta_{t-1} - \gamma \widehat{m_t}/
            \big(\sqrt{\widehat{v_t}^{max}} + \epsilon \big)                                 \
        &amp;\hspace{5mm}\textbf{else}                                                           \
        &amp;\hspace{10mm}\theta_t \leftarrow \theta_{t-1} - \gamma \widehat{m_t}/
            \big(\sqrt{\widehat{v_t}} + \epsilon \big)                                       \
        &amp;\rule{110mm}{0.4pt}                                                          \[-1.ex]
        &amp;\bf{return} :  \theta_t                                                     \[-1.ex]
        &amp;\rule{110mm}{0.4pt}                                                          \[-1.ex]
   \end{aligned}</p>
<p>For further details regarding the algorithm we refer to <code>Adam: A Method for Stochastic Optimization</code>_.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>params</code></td>
        <td><code>iterable</code></td>
        <td><p>iterable of parameters to optimize or dicts defining
parameter groups</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>lr</code></td>
        <td><code>float</code></td>
        <td><p>learning rate (default: 1e-3)</p></td>
        <td><code>0.001</code></td>
      </tr>
      <tr>
        <td><code>betas</code></td>
        <td><code>Tuple[float, float]</code></td>
        <td><p>coefficients used for computing
running averages of gradient and its square (default: (0.9, 0.999))</p></td>
        <td><code>(0.9, 0.999)</code></td>
      </tr>
      <tr>
        <td><code>eps</code></td>
        <td><code>float</code></td>
        <td><p>term added to the denominator to improve
numerical stability (default: 1e-8)</p></td>
        <td><code>1e-08</code></td>
      </tr>
      <tr>
        <td><code>weight_decay</code></td>
        <td><code>float</code></td>
        <td><p>weight decay (L2 penalty) (default: 0)</p></td>
        <td><code>0</code></td>
      </tr>
      <tr>
        <td><code>amsgrad</code></td>
        <td><code>boolean</code></td>
        <td><p>whether to use the AMSGrad variant of this
algorithm from the paper <code>On the Convergence of Adam and Beyond</code>_
(default: False)</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>      <p>.. _Adam: A Method for Stochastic Optimization:
    https://arxiv.org/abs/1412.6980
.. _On the Convergence of Adam and Beyond:
    https://openreview.net/forum?id=ryQu7f-RZ</p>

        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">Adam</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Implements Adam algorithm.</span>

<span class="sd">    .. math::</span>
<span class="sd">       \begin{aligned}</span>
<span class="sd">            &amp;\rule{110mm}{0.4pt}                                                                 \\</span>
<span class="sd">            &amp;\textbf{input}      : \gamma \text{ (lr)}, \beta_1, \beta_2</span>
<span class="sd">                \text{ (betas)},\theta_0 \text{ (params)},f(\theta) \text{ (objective)}          \\</span>
<span class="sd">            &amp;\hspace{13mm}      \lambda \text{ (weight decay)},  \: amsgrad                      \\</span>
<span class="sd">            &amp;\textbf{initialize} :  m_0 \leftarrow 0 \text{ ( first moment)},</span>
<span class="sd">                v_0\leftarrow 0 \text{ (second moment)},\: \widehat{v_0}^{max}\leftarrow 0\\[-1.ex]</span>
<span class="sd">            &amp;\rule{110mm}{0.4pt}                                                                 \\</span>
<span class="sd">            &amp;\textbf{for} \: t=1 \: \textbf{to} \: \ldots \: \textbf{do}                         \\</span>
<span class="sd">            &amp;\hspace{5mm}g_t           \leftarrow   \nabla_{\theta} f_t (\theta_{t-1})           \\</span>
<span class="sd">            &amp;\hspace{5mm}\textbf{if} \: \lambda \neq 0                                           \\</span>
<span class="sd">            &amp;\hspace{10mm} g_t \leftarrow g_t + \lambda  \theta_{t-1}                            \\</span>
<span class="sd">            &amp;\hspace{5mm}m_t           \leftarrow   \beta_1 m_{t-1} + (1 - \beta_1) g_t          \\</span>
<span class="sd">            &amp;\hspace{5mm}v_t           \leftarrow   \beta_2 v_{t-1} + (1-\beta_2) g^2_t          \\</span>
<span class="sd">            &amp;\hspace{5mm}\widehat{m_t} \leftarrow   m_t/\big(1-\beta_1^t \big)                   \\</span>
<span class="sd">            &amp;\hspace{5mm}\widehat{v_t} \leftarrow   v_t/\big(1-\beta_2^t \big)                   \\</span>
<span class="sd">            &amp;\hspace{5mm}\textbf{if} \: amsgrad                                                  \\</span>
<span class="sd">            &amp;\hspace{10mm}\widehat{v_t}^{max} \leftarrow \mathrm{max}(\widehat{v_t}^{max},</span>
<span class="sd">                \widehat{v_t})                                                                   \\</span>
<span class="sd">            &amp;\hspace{10mm}\theta_t \leftarrow \theta_{t-1} - \gamma \widehat{m_t}/</span>
<span class="sd">                \big(\sqrt{\widehat{v_t}^{max}} + \epsilon \big)                                 \\</span>
<span class="sd">            &amp;\hspace{5mm}\textbf{else}                                                           \\</span>
<span class="sd">            &amp;\hspace{10mm}\theta_t \leftarrow \theta_{t-1} - \gamma \widehat{m_t}/</span>
<span class="sd">                \big(\sqrt{\widehat{v_t}} + \epsilon \big)                                       \\</span>
<span class="sd">            &amp;\rule{110mm}{0.4pt}                                                          \\[-1.ex]</span>
<span class="sd">            &amp;\bf{return} \:  \theta_t                                                     \\[-1.ex]</span>
<span class="sd">            &amp;\rule{110mm}{0.4pt}                                                          \\[-1.ex]</span>
<span class="sd">       \end{aligned}</span>

<span class="sd">    For further details regarding the algorithm we refer to `Adam: A Method for Stochastic Optimization`_.</span>

<span class="sd">    Args:</span>
<span class="sd">        params (iterable): iterable of parameters to optimize or dicts defining</span>
<span class="sd">            parameter groups</span>
<span class="sd">        lr (float, optional): learning rate (default: 1e-3)</span>
<span class="sd">        betas (Tuple[float, float], optional): coefficients used for computing</span>
<span class="sd">            running averages of gradient and its square (default: (0.9, 0.999))</span>
<span class="sd">        eps (float, optional): term added to the denominator to improve</span>
<span class="sd">            numerical stability (default: 1e-8)</span>
<span class="sd">        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)</span>
<span class="sd">        amsgrad (boolean, optional): whether to use the AMSGrad variant of this</span>
<span class="sd">            algorithm from the paper `On the Convergence of Adam and Beyond`_</span>
<span class="sd">            (default: False)</span>

<span class="sd">    .. _Adam\: A Method for Stochastic Optimization:</span>
<span class="sd">        https://arxiv.org/abs/1412.6980</span>
<span class="sd">    .. _On the Convergence of Adam and Beyond:</span>
<span class="sd">        https://openreview.net/forum?id=ryQu7f-RZ</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
                 <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">amsgrad</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">lr</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid learning rate: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="p">))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">eps</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid epsilon value: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">eps</span><span class="p">))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">betas</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid beta parameter at index 0: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">betas</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">betas</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid beta parameter at index 1: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">betas</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">weight_decay</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid weight_decay value: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">))</span>
        <span class="n">defaults</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="n">betas</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span>
                        <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span> <span class="n">amsgrad</span><span class="o">=</span><span class="n">amsgrad</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Adam</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">defaults</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Adam</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__setstate__</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">group</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">&#39;amsgrad&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">closure</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Performs a single optimization step.</span>

<span class="sd">        Args:</span>
<span class="sd">            closure (callable, optional): A closure that reevaluates the model</span>
<span class="sd">                and returns the loss.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">closure</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">():</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">closure</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">params_with_grad</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">grads</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">exp_avgs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">exp_avg_sqs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">max_exp_avg_sqs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">state_steps</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;betas&#39;</span><span class="p">]</span>

            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">params_with_grad</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Adam does not support sparse gradients, please consider SparseAdam instead&#39;</span><span class="p">)</span>
                    <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>

                    <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">[</span><span class="n">p</span><span class="p">]</span>
                    <span class="c1"># Lazy state initialization</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">state</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                        <span class="c1"># Exponential moving average of gradient values</span>
                        <span class="n">state</span><span class="p">[</span><span class="s1">&#39;exp_avg&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">)</span>
                        <span class="c1"># Exponential moving average of squared gradient values</span>
                        <span class="n">state</span><span class="p">[</span><span class="s1">&#39;exp_avg_sq&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;amsgrad&#39;</span><span class="p">]:</span>
                            <span class="c1"># Maintains max of all exp. moving avg. of sq. grad. values</span>
                            <span class="n">state</span><span class="p">[</span><span class="s1">&#39;max_exp_avg_sq&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">)</span>

                    <span class="n">exp_avgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s1">&#39;exp_avg&#39;</span><span class="p">])</span>
                    <span class="n">exp_avg_sqs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s1">&#39;exp_avg_sq&#39;</span><span class="p">])</span>

                    <span class="k">if</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;amsgrad&#39;</span><span class="p">]:</span>
                        <span class="n">max_exp_avg_sqs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s1">&#39;max_exp_avg_sq&#39;</span><span class="p">])</span>

                    <span class="c1"># update the steps for each param group update</span>
                    <span class="n">state</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="c1"># record the step after step update</span>
                    <span class="n">state_steps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">])</span>

            <span class="n">F</span><span class="o">.</span><span class="n">adam</span><span class="p">(</span><span class="n">params_with_grad</span><span class="p">,</span>
                   <span class="n">grads</span><span class="p">,</span>
                   <span class="n">exp_avgs</span><span class="p">,</span>
                   <span class="n">exp_avg_sqs</span><span class="p">,</span>
                   <span class="n">max_exp_avg_sqs</span><span class="p">,</span>
                   <span class="n">state_steps</span><span class="p">,</span>
                   <span class="n">amsgrad</span><span class="o">=</span><span class="n">group</span><span class="p">[</span><span class="s1">&#39;amsgrad&#39;</span><span class="p">],</span>
                   <span class="n">beta1</span><span class="o">=</span><span class="n">beta1</span><span class="p">,</span>
                   <span class="n">beta2</span><span class="o">=</span><span class="n">beta2</span><span class="p">,</span>
                   <span class="n">lr</span><span class="o">=</span><span class="n">group</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">],</span>
                   <span class="n">weight_decay</span><span class="o">=</span><span class="n">group</span><span class="p">[</span><span class="s1">&#39;weight_decay&#39;</span><span class="p">],</span>
                   <span class="n">eps</span><span class="o">=</span><span class="n">group</span><span class="p">[</span><span class="s1">&#39;eps&#39;</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">loss</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">











  <div class="doc doc-object doc-method">



<h4 id="hover.core.neural.VectorNet.DEFAULT_OPTIM_CLS.step" class="doc doc-heading">
<code class="highlight language-python"><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">closure</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


</h4>

    <div class="doc doc-contents ">

      <p>Performs a single optimization step.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>closure</code></td>
        <td><code>callable</code></td>
        <td><p>A closure that reevaluates the model
and returns the loss.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">closure</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Performs a single optimization step.</span>

<span class="sd">    Args:</span>
<span class="sd">        closure (callable, optional): A closure that reevaluates the model</span>
<span class="sd">            and returns the loss.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">closure</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">():</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">closure</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
        <span class="n">params_with_grad</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">exp_avgs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">exp_avg_sqs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">max_exp_avg_sqs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">state_steps</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;betas&#39;</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">params_with_grad</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Adam does not support sparse gradients, please consider SparseAdam instead&#39;</span><span class="p">)</span>
                <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>

                <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">[</span><span class="n">p</span><span class="p">]</span>
                <span class="c1"># Lazy state initialization</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">state</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="c1"># Exponential moving average of gradient values</span>
                    <span class="n">state</span><span class="p">[</span><span class="s1">&#39;exp_avg&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">)</span>
                    <span class="c1"># Exponential moving average of squared gradient values</span>
                    <span class="n">state</span><span class="p">[</span><span class="s1">&#39;exp_avg_sq&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;amsgrad&#39;</span><span class="p">]:</span>
                        <span class="c1"># Maintains max of all exp. moving avg. of sq. grad. values</span>
                        <span class="n">state</span><span class="p">[</span><span class="s1">&#39;max_exp_avg_sq&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">)</span>

                <span class="n">exp_avgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s1">&#39;exp_avg&#39;</span><span class="p">])</span>
                <span class="n">exp_avg_sqs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s1">&#39;exp_avg_sq&#39;</span><span class="p">])</span>

                <span class="k">if</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;amsgrad&#39;</span><span class="p">]:</span>
                    <span class="n">max_exp_avg_sqs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s1">&#39;max_exp_avg_sq&#39;</span><span class="p">])</span>

                <span class="c1"># update the steps for each param group update</span>
                <span class="n">state</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="c1"># record the step after step update</span>
                <span class="n">state_steps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">])</span>

        <span class="n">F</span><span class="o">.</span><span class="n">adam</span><span class="p">(</span><span class="n">params_with_grad</span><span class="p">,</span>
               <span class="n">grads</span><span class="p">,</span>
               <span class="n">exp_avgs</span><span class="p">,</span>
               <span class="n">exp_avg_sqs</span><span class="p">,</span>
               <span class="n">max_exp_avg_sqs</span><span class="p">,</span>
               <span class="n">state_steps</span><span class="p">,</span>
               <span class="n">amsgrad</span><span class="o">=</span><span class="n">group</span><span class="p">[</span><span class="s1">&#39;amsgrad&#39;</span><span class="p">],</span>
               <span class="n">beta1</span><span class="o">=</span><span class="n">beta1</span><span class="p">,</span>
               <span class="n">beta2</span><span class="o">=</span><span class="n">beta2</span><span class="p">,</span>
               <span class="n">lr</span><span class="o">=</span><span class="n">group</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">],</span>
               <span class="n">weight_decay</span><span class="o">=</span><span class="n">group</span><span class="p">[</span><span class="s1">&#39;weight_decay&#39;</span><span class="p">],</span>
               <span class="n">eps</span><span class="o">=</span><span class="n">group</span><span class="p">[</span><span class="s1">&#39;eps&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>





  <div class="doc doc-object doc-method">



<h3 id="hover.core.neural.VectorNet.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">,</span> <span class="n">architecture</span><span class="p">,</span> <span class="n">state_dict_path</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">backup_state_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optimizer_cls</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimizer_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">example_input</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <details class="note" open="open">
<summary>Create the <code>VectorNet</code>, loading parameters if available.</summary>
<table>
<thead>
<tr>
<th align="left">Param</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><code>vectorizer</code></td>
<td align="left"><code>callable</code></td>
<td align="left">the feature -&gt; vector function</td>
</tr>
<tr>
<td align="left"><code>architecture</code></td>
<td align="left"><code>class</code></td>
<td align="left">a <code>torch.nn.Module</code> child class</td>
</tr>
<tr>
<td align="left"><code>state_dict_path</code></td>
<td align="left"><code>str</code></td>
<td align="left">path to a (could-be-empty) <code>torch</code> state dict</td>
</tr>
<tr>
<td align="left"><code>labels</code></td>
<td align="left"><code>list</code></td>
<td align="left">list of <code>str</code> classification labels</td>
</tr>
<tr>
<td align="left"><code>backup_state_dict</code></td>
<td align="left"><code>bool</code></td>
<td align="left">whether to backup the loaded state dict</td>
</tr>
<tr>
<td align="left"><code>optimizer_cls</code></td>
<td align="left"><code>subclass of torch.optim.Optimizer</code></td>
<td align="left">pytorch optimizer class</td>
</tr>
<tr>
<td align="left"><code>optimizer_kwargs</code></td>
<td align="left"><code>dict</code></td>
<td align="left">pytorch optimizer kwargs</td>
</tr>
<tr>
<td align="left"><code>verbose</code></td>
<td align="left"><code>int</code></td>
<td align="left">logging verbosity level</td>
</tr>
<tr>
<td align="left"><code>example_input</code></td>
<td align="left">any</td>
<td align="left">example input to the vectorizer</td>
</tr>
</tbody>
</table>
</details>

        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">vectorizer</span><span class="p">,</span>
    <span class="n">architecture</span><span class="p">,</span>
    <span class="n">state_dict_path</span><span class="p">,</span>
    <span class="n">labels</span><span class="p">,</span>
    <span class="n">backup_state_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">optimizer_cls</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">optimizer_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">example_input</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ???+ note &quot;Create the `VectorNet`, loading parameters if available.&quot;</span>

<span class="sd">        | Param             | Type       | Description                          |</span>
<span class="sd">        | :---------------- | :--------- | :----------------------------------- |</span>
<span class="sd">        | `vectorizer`      | `callable` | the feature -&gt; vector function       |</span>
<span class="sd">        | `architecture`    | `class`    | a `torch.nn.Module` child class      |</span>
<span class="sd">        | `state_dict_path` | `str`      | path to a (could-be-empty) `torch` state dict |</span>
<span class="sd">        | `labels`          | `list`     | list of `str` classification labels  |</span>
<span class="sd">        | `backup_state_dict` | `bool`   | whether to backup the loaded state dict |</span>
<span class="sd">        | `optimizer_cls`   | `subclass of torch.optim.Optimizer` | pytorch optimizer class |</span>
<span class="sd">        | `optimizer_kwargs`  | `dict`   | pytorch optimizer kwargs             |</span>
<span class="sd">        | `verbose`         | `int`      | logging verbosity level              |</span>
<span class="sd">        | `example_input`   | any        | example input to the vectorizer      |</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
        <span class="n">verbose</span><span class="p">,</span> <span class="nb">int</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Expected verbose as int, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">verbose</span><span class="p">)</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">verbose</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">vectorizer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">example_input</span> <span class="o">=</span> <span class="n">example_input</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span> <span class="o">=</span> <span class="n">architecture</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_label_conversion</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_dynamic_params</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1"># set a path to store updated parameters</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nn_update_path</span> <span class="o">=</span> <span class="n">state_dict_path</span>

    <span class="k">if</span> <span class="n">backup_state_dict</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">state_dict_path</span><span class="p">):</span>
        <span class="n">state_dict_backup_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">state_dict_path</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">current_time</span><span class="p">(</span><span class="s1">&#39;%Y%m</span><span class="si">%d</span><span class="s1">%H%M%S&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">copyfile</span><span class="p">(</span><span class="n">state_dict_path</span><span class="p">,</span> <span class="n">state_dict_backup_path</span><span class="p">)</span>

    <span class="c1"># initialize an optimizer object and a dict to hold dynamic parameters</span>
    <span class="n">optimizer_cls</span> <span class="o">=</span> <span class="n">optimizer_cls</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">DEFAULT_OPTIM_CLS</span>
    <span class="n">optimizer_kwargs</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">optimizer_kwargs</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">DEFAULT_OPTIM_KWARGS</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="p">)</span>

    <span class="k">def</span> <span class="nf">callback_reset_nn_optimizer</span><span class="p">():</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Callback function which has access to optimizer init settings.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nn_optimizer</span> <span class="o">=</span> <span class="n">optimizer_cls</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nn_optimizer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Expected an optimizer, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn_optimizer</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dynamic_params</span><span class="p">[</span><span class="s2">&quot;optimizer&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimizer_kwargs</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_callback_reset_nn_optimizer</span> <span class="o">=</span> <span class="n">callback_reset_nn_optimizer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_nn</span><span class="p">(</span><span class="n">use_existing_state_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_setup_widgets</span><span class="p">()</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="hover.core.neural.VectorNet.adjust_optimizer_params" class="doc doc-heading">
<code class="highlight language-python"><span class="n">adjust_optimizer_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <details class="note" open="open">
<summary>Dynamically change parameters of the neural net optimizer.</summary>
<ul>
<li>Intended to be polymorphic in child classes and to be called per epoch.</li>
</ul>
</details>

        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">adjust_optimizer_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ???+ note &quot;Dynamically change parameters of the neural net optimizer.&quot;</span>

<span class="sd">        - Intended to be polymorphic in child classes and to be called per epoch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">_group</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
        <span class="n">_group</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dynamic_params</span><span class="p">[</span><span class="s2">&quot;optimizer&quot;</span><span class="p">])</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="hover.core.neural.VectorNet.auto_adjust_setup" class="doc doc-heading">
<code class="highlight language-python"><span class="n">auto_adjust_setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">auto_skip</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <details class="note" open="open">
<summary>Auto-(re)create label encoder/decoder and neural net.</summary>
<p>Intended to be called in and out of the constructor.</p>
<table>
<thead>
<tr>
<th align="left">Param</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><code>labels</code></td>
<td align="left"><code>list</code></td>
<td align="left">list of <code>str</code> classification labels</td>
</tr>
<tr>
<td align="left"><code>auto_skip</code></td>
<td align="left"><code>bool</code></td>
<td align="left">skip when labels did not change</td>
</tr>
</tbody>
</table>
</details>

        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">auto_adjust_setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">auto_skip</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ???+ note &quot;Auto-(re)create label encoder/decoder and neural net.&quot;</span>

<span class="sd">        Intended to be called in and out of the constructor.</span>

<span class="sd">        | Param             | Type       | Description                          |</span>
<span class="sd">        | :---------------- | :--------- | :----------------------------------- |</span>
<span class="sd">        | `labels`          | `list`     | list of `str` classification labels  |</span>
<span class="sd">        | `auto_skip`       | `bool`     | skip when labels did not change      |</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># sanity check and skip</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="nb">list</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Expected a list of labels, got </span><span class="si">{</span><span class="n">labels</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="c1"># if the sequence of labels matches label encoder exactly, skip</span>
    <span class="n">label_match_flag</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">==</span> <span class="nb">sorted</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">auto_skip</span> <span class="ow">and</span> <span class="n">label_match_flag</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">setup_label_conversion</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_nn</span><span class="p">(</span><span class="n">use_existing_state_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_good</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;adjusted to new list of labels: </span><span class="si">{</span><span class="n">labels</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="hover.core.neural.VectorNet.evaluate" class="doc doc-heading">
<code class="highlight language-python"><span class="n">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dev_loader</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <details class="note" open="open">
<summary>Evaluate the VecNet against a dev set.</summary>
<table>
<thead>
<tr>
<th align="left">Param</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><code>dev_loader</code></td>
<td align="left"><code>torch.utils.data.DataLoader</code></td>
<td align="left">dev set</td>
</tr>
</tbody>
</table>
</details>

        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dev_loader</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ???+ note &quot;Evaluate the VecNet against a dev set.&quot;</span>

<span class="sd">        | Param        | Type         | Description                |</span>
<span class="sd">        | :----------- | :----------- | :------------------------- |</span>
<span class="sd">        | `dev_loader` | `torch.utils.data.DataLoader` | dev set   |</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">true</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">loaded_input</span><span class="p">,</span> <span class="n">loaded_output</span><span class="p">,</span> <span class="n">_idx</span> <span class="ow">in</span> <span class="n">dev_loader</span><span class="p">:</span>
        <span class="n">_input_tensor</span> <span class="o">=</span> <span class="n">loaded_input</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">_output_tensor</span> <span class="o">=</span> <span class="n">loaded_output</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

        <span class="n">_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="p">(</span><span class="n">_input_tensor</span><span class="p">)</span>
        <span class="n">_true_batch</span> <span class="o">=</span> <span class="n">_output_tensor</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">_pred_batch</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">true</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_true_batch</span><span class="p">)</span>
        <span class="n">pred</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_pred_batch</span><span class="p">)</span>
    <span class="n">true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">true</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">classification_accuracy</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
    <span class="n">conf_mat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">log_info</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dynamic_params</span><span class="p">)</span>
        <span class="n">log_info</span><span class="p">[</span><span class="s2">&quot;performance&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;Acc </span><span class="si">{0:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="p">(</span>
            <span class="s2">&quot;</span><span class="si">{0: &lt;80}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="s2">&quot;Eval: Epoch </span><span class="si">{epoch}</span><span class="s2"> </span><span class="si">{performance}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="n">log_info</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">conf_mat</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="hover.core.neural.VectorNet.from_module" class="doc doc-heading">
<code class="highlight language-python"><span class="n">from_module</span><span class="p">(</span><span class="n">model_module</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-classmethod"><code>classmethod</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <details class="note" open="open">
<summary>Create a VectorNet model from a loadable module.</summary>
<table>
<thead>
<tr>
<th align="left">Param</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><code>model_module</code></td>
<td align="left"><code>module</code> or <code>str</code></td>
<td align="left">(path to) a local Python workspace module which contains a get_vectorizer() callable, get_architecture() callable, and a get_state_dict_path() callable</td>
</tr>
<tr>
<td align="left"><code>labels</code></td>
<td align="left"><code>list</code></td>
<td align="left">list of <code>str</code> classification labels</td>
</tr>
<tr>
<td align="left"><code>**kwargs</code></td>
<td align="left"></td>
<td align="left">forwarded to <code>self.__init__()</code> constructor</td>
</tr>
</tbody>
</table>
</details>

        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">from_module</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">model_module</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ???+ note &quot;Create a VectorNet model from a loadable module.&quot;</span>

<span class="sd">        | Param          | Type       | Description                          |</span>
<span class="sd">        | :------------- | :--------- | :----------------------------------- |</span>
<span class="sd">        | `model_module` | `module` or `str` | (path to) a local Python workspace module which contains a get_vectorizer() callable, get_architecture() callable, and a get_state_dict_path() callable |</span>
<span class="sd">        | `labels`       | `list`     | list of `str` classification labels  |</span>
<span class="sd">        | `**kwargs`     |      | forwarded to `self.__init__()` constructor |</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model_module</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">importlib</span> <span class="kn">import</span> <span class="n">import_module</span>

        <span class="n">model_module</span> <span class="o">=</span> <span class="n">import_module</span><span class="p">(</span><span class="n">model_module</span><span class="p">)</span>

    <span class="c1"># Load the model by retrieving the inp-to-vec function, architecture, and state dict</span>
    <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span>
        <span class="n">model_module</span><span class="o">.</span><span class="n">get_vectorizer</span><span class="p">(),</span>
        <span class="n">model_module</span><span class="o">.</span><span class="n">get_architecture</span><span class="p">(),</span>
        <span class="n">model_module</span><span class="o">.</span><span class="n">get_state_dict_path</span><span class="p">(),</span>
        <span class="n">labels</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="hover.core.neural.VectorNet.load" class="doc doc-heading">
<code class="highlight language-python"><span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">load_path</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <details class="note" open="open">
<summary>Load neural net parameters if possible.</summary>
<p>Can be directed to a custom state dict.</p>
<table>
<thead>
<tr>
<th align="left">Param</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><code>load_path</code></td>
<td align="left"><code>str</code></td>
<td align="left">path to a <code>torch</code> state dict</td>
</tr>
</tbody>
</table>
</details>

        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">load_path</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ???+ note &quot;Load neural net parameters if possible.&quot;</span>

<span class="sd">        Can be directed to a custom state dict.</span>

<span class="sd">        | Param       | Type       | Description                  |</span>
<span class="sd">        | :---------- | :--------- | :--------------------------- |</span>
<span class="sd">        | `load_path` | `str`      | path to a `torch` state dict |</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">load_path</span> <span class="o">=</span> <span class="n">load_path</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_update_path</span>
    <span class="c1"># if the architecture cannot match the state dict, skip the load and warn</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">load_path</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;loaded state dict </span><span class="si">{</span><span class="n">load_path</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;load VectorNet state path failed with </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="hover.core.neural.VectorNet.manifold_trajectory" class="doc doc-heading">
<code class="highlight language-python"><span class="n">manifold_trajectory</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inps</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;umap&#39;</span><span class="p">,</span> <span class="n">reducer_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">spline_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <details class="note" open="open">
<summary>Compute a propagation trajectory of the dataset manifold through the neural net.</summary>
<ol>
<li>vectorize inps</li>
<li>forward propagate, keeping intermediates</li>
<li>fit intermediates to N-D manifolds</li>
<li>fit manifolds using Procrustes shape analysis</li>
<li>fit shapes to trajectory splines</li>
</ol>
<table>
<thead>
<tr>
<th align="left">Param</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><code>inps</code></td>
<td align="left">dynamic</td>
<td align="left">(a list of) input features to vectorize</td>
</tr>
<tr>
<td align="left"><code>method</code></td>
<td align="left"><code>str</code></td>
<td align="left">reduction method: <code>"umap"</code> or <code>"ivis"</code></td>
</tr>
<tr>
<td align="left"><code>reducer_kwargs</code></td>
<td align="left"></td>
<td align="left">kwargs to forward to dimensionality reduction</td>
</tr>
<tr>
<td align="left"><code>spline_kwargs</code></td>
<td align="left"></td>
<td align="left">kwargs to forward to spline calculation</td>
</tr>
</tbody>
</table>
</details>

        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">manifold_trajectory</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">inps</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;umap&quot;</span><span class="p">,</span> <span class="n">reducer_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">spline_kwargs</span><span class="o">=</span><span class="kc">None</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ???+ note &quot;Compute a propagation trajectory of the dataset manifold through the neural net.&quot;</span>

<span class="sd">        1. vectorize inps</span>
<span class="sd">        2. forward propagate, keeping intermediates</span>
<span class="sd">        3. fit intermediates to N-D manifolds</span>
<span class="sd">        4. fit manifolds using Procrustes shape analysis</span>
<span class="sd">        5. fit shapes to trajectory splines</span>

<span class="sd">        | Param    | Type    | Description                          |</span>
<span class="sd">        | :------- | :------ | :----------------------------------- |</span>
<span class="sd">        | `inps`   | dynamic | (a list of) input features to vectorize |</span>
<span class="sd">        | `method` | `str`   | reduction method: `&quot;umap&quot;` or `&quot;ivis&quot;`  |</span>
<span class="sd">        | `reducer_kwargs` | | kwargs to forward to dimensionality reduction |</span>
<span class="sd">        | `spline_kwargs` | | kwargs to forward to spline calculation |</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">hover.core.representation.manifold</span> <span class="kn">import</span> <span class="n">LayerwiseManifold</span>
    <span class="kn">from</span> <span class="nn">hover.core.representation.trajectory</span> <span class="kn">import</span> <span class="n">manifold_spline</span>

    <span class="n">reducer_kwargs</span> <span class="o">=</span> <span class="n">reducer_kwargs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">spline_kwargs</span> <span class="o">=</span> <span class="n">spline_kwargs</span> <span class="ow">or</span> <span class="p">{}</span>

    <span class="c1"># step 1 &amp; 2</span>
    <span class="n">vectors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="p">(</span><span class="n">_inp</span><span class="p">)</span> <span class="k">for</span> <span class="n">_inp</span> <span class="ow">in</span> <span class="n">inps</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">intermediates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">eval_per_layer</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
    <span class="n">intermediates</span> <span class="o">=</span> <span class="p">[</span><span class="n">_tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">_tensor</span> <span class="ow">in</span> <span class="n">intermediates</span><span class="p">]</span>

    <span class="c1"># step 3 &amp; 4</span>
    <span class="n">LM</span> <span class="o">=</span> <span class="n">LayerwiseManifold</span><span class="p">(</span><span class="n">intermediates</span><span class="p">)</span>
    <span class="n">LM</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span> <span class="o">**</span><span class="n">reducer_kwargs</span><span class="p">)</span>
    <span class="n">seq_arr</span><span class="p">,</span> <span class="n">disparities</span> <span class="o">=</span> <span class="n">LM</span><span class="o">.</span><span class="n">procrustes</span><span class="p">()</span>
    <span class="n">seq_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">seq_arr</span><span class="p">)</span>

    <span class="c1"># step 5</span>
    <span class="n">traj_arr</span> <span class="o">=</span> <span class="n">manifold_spline</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">seq_arr</span><span class="p">),</span> <span class="o">**</span><span class="n">spline_kwargs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">traj_arr</span><span class="p">,</span> <span class="n">seq_arr</span><span class="p">,</span> <span class="n">disparities</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="hover.core.neural.VectorNet.predict_proba" class="doc doc-heading">
<code class="highlight language-python"><span class="n">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inps</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <details class="note" open="open">
<summary>End-to-end single/multi-piece prediction from inp to class probabilities.</summary>
<table>
<thead>
<tr>
<th align="left">Param</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><code>inps</code></td>
<td align="left">dynamic</td>
<td align="left">(a list of) input features to vectorize</td>
</tr>
</tbody>
</table>
</details>

        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inps</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ???+ note &quot;End-to-end single/multi-piece prediction from inp to class probabilities.&quot;</span>
<span class="sd">        | Param  | Type    | Description                          |</span>
<span class="sd">        | :----- | :------ | :----------------------------------- |</span>
<span class="sd">        | `inps` | dynamic | (a list of) input features to vectorize |</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># if the input is a single piece of inp, cast it to a list</span>
    <span class="n">FLAG_SINGLE</span> <span class="o">=</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inps</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">FLAG_SINGLE</span><span class="p">:</span>
        <span class="n">inps</span> <span class="o">=</span> <span class="p">[</span><span class="n">inps</span><span class="p">]</span>

    <span class="c1"># the actual prediction</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">vectors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="p">(</span><span class="n">_inp</span><span class="p">)</span> <span class="k">for</span> <span class="n">_inp</span> <span class="ow">in</span> <span class="n">inps</span><span class="p">]))</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="c1"># inverse-cast if applicable</span>
    <span class="k">if</span> <span class="n">FLAG_SINGLE</span><span class="p">:</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">probs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">probs</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="hover.core.neural.VectorNet.prepare_loader" class="doc doc-heading">
<code class="highlight language-python"><span class="n">prepare_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <details class="note" open="open">
<summary>Create dataloader from <code>SupervisableDataset</code> with implied vectorizer(s).</summary>
<table>
<thead>
<tr>
<th align="left">Param</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><code>dataset</code></td>
<td align="left"><code>hover.core.dataset.SupervisableDataset</code></td>
<td align="left">the dataset to load</td>
</tr>
<tr>
<td align="left"><code>key</code></td>
<td align="left"><code>str</code></td>
<td align="left">"train", "dev", or "test"</td>
</tr>
<tr>
<td align="left"><code>**kwargs</code></td>
<td align="left"></td>
<td align="left">forwarded to <code>dataset.loader()</code></td>
</tr>
</tbody>
</table>
</details>

        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">prepare_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ???+ note &quot;Create dataloader from `SupervisableDataset` with implied vectorizer(s).&quot;</span>

<span class="sd">        | Param      | Type  | Description                |</span>
<span class="sd">        | :--------- | :---- | :------------------------- |</span>
<span class="sd">        | `dataset`  | `hover.core.dataset.SupervisableDataset` | the dataset to load |</span>
<span class="sd">        | `key`      | `str` | &quot;train&quot;, &quot;dev&quot;, or &quot;test&quot;  |</span>
<span class="sd">        | `**kwargs` | | forwarded to `dataset.loader()`  |</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">dataset</span><span class="o">.</span><span class="n">loader</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="hover.core.neural.VectorNet.save" class="doc doc-heading">
<code class="highlight language-python"><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <details class="note" open="open">
<summary>Save the current state dict with authorization to overwrite.</summary>
<table>
<thead>
<tr>
<th align="left">Param</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><code>save_path</code></td>
<td align="left"><code>str</code></td>
<td align="left">option alternative path to state dict</td>
</tr>
</tbody>
</table>
</details>

        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ???+ note &quot;Save the current state dict with authorization to overwrite.&quot;</span>
<span class="sd">        | Param       | Type  | Description                           |</span>
<span class="sd">        | :---------- | :---- | :------------------------------------ |</span>
<span class="sd">        | `save_path` | `str` | option alternative path to state dict |</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">save_path</span> <span class="o">=</span> <span class="n">save_path</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_update_path</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">save_path</span><span class="p">)</span>
    <span class="n">verb</span> <span class="o">=</span> <span class="s2">&quot;overwrote&quot;</span> <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;saved&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">verb</span><span class="si">}</span><span class="s2"> state dict </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="hover.core.neural.VectorNet.setup_label_conversion" class="doc doc-heading">
<code class="highlight language-python"><span class="n">setup_label_conversion</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <details class="note" open="open">
<summary>Set up label encoder/decoder and number of classes.</summary>
<table>
<thead>
<tr>
<th align="left">Param</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><code>labels</code></td>
<td align="left"><code>list</code></td>
<td align="left">list of <code>str</code> classification labels</td>
</tr>
</tbody>
</table>
</details>

        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">setup_label_conversion</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ???+ note &quot;Set up label encoder/decoder and number of classes.&quot;</span>

<span class="sd">        | Param             | Type       | Description                          |</span>
<span class="sd">        | :---------------- | :--------- | :----------------------------------- |</span>
<span class="sd">        | `labels`          | `list`     | list of `str` classification labels  |</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">_label</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="p">)}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">label_decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">_label</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="p">)}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="hover.core.neural.VectorNet.setup_nn" class="doc doc-heading">
<code class="highlight language-python"><span class="n">setup_nn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_existing_state_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <details class="note" open="open">
<summary>Set up neural network and optimizers.</summary>
<p>Intended to be called in and out of the constructor.</p>
<ul>
<li>will try to load parameters from state dict by default</li>
<li>option to override and discard previous state dict<ul>
<li>often used when the classification targets have changed</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th align="left">Param</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><code>labels</code></td>
<td align="left"><code>list</code></td>
<td align="left">list of <code>str</code> classification labels</td>
</tr>
<tr>
<td align="left"><code>use_existing_state_dict</code></td>
<td align="left"><code>bool</code></td>
<td align="left">whether to use existing state dict</td>
</tr>
</tbody>
</table>
</details>

        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">setup_nn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_existing_state_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ???+ note &quot;Set up neural network and optimizers.&quot;</span>

<span class="sd">        Intended to be called in and out of the constructor.</span>

<span class="sd">        -   will try to load parameters from state dict by default</span>
<span class="sd">        -   option to override and discard previous state dict</span>
<span class="sd">            -   often used when the classification targets have changed</span>

<span class="sd">        | Param                     | Type       | Description                          |</span>
<span class="sd">        | :------------------------ | :--------- | :----------------------------------- |</span>
<span class="sd">        | `labels`                  | `list`     | list of `str` classification labels  |</span>
<span class="sd">        | `use_existing_state_dict` | `bool`     | whether to use existing state dict   |</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># set up vectorizer and the neural network with appropriate dimensions</span>
    <span class="n">vec_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">example_input</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">(</span><span class="n">vec_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_callback_reset_nn_optimizer</span><span class="p">()</span>

    <span class="n">state_dict_exists</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn_update_path</span><span class="p">)</span>
    <span class="c1"># if state dict exists, load it (when consistent) or overwrite</span>
    <span class="k">if</span> <span class="n">state_dict_exists</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">use_existing_state_dict</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn_update_path</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn_update_path</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_good</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;reset neural net: in </span><span class="si">{</span><span class="n">vec_dim</span><span class="si">}</span><span class="s2"> out </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="hover.core.neural.VectorNet.train" class="doc doc-heading">
<code class="highlight language-python"><span class="n">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">dev_loader</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <details class="note" open="open">
<summary>Train the neural network part of the VecNet.</summary>
<ul>
<li>intended to be coupled with self.train_batch().</li>
</ul>
<table>
<thead>
<tr>
<th align="left">Param</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><code>train_loader</code></td>
<td align="left"><code>torch.utils.data.DataLoader</code></td>
<td align="left">train set</td>
</tr>
<tr>
<td align="left"><code>dev_loader</code></td>
<td align="left"><code>torch.utils.data.DataLoader</code></td>
<td align="left">dev set</td>
</tr>
<tr>
<td align="left"><code>epochs</code></td>
<td align="left"><code>int</code></td>
<td align="left">number of epochs to train</td>
</tr>
</tbody>
</table>
</details>

        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">dev_loader</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ???+ note &quot;Train the neural network part of the VecNet.&quot;</span>

<span class="sd">        - intended to be coupled with self.train_batch().</span>

<span class="sd">        | Param          | Type         | Description                |</span>
<span class="sd">        | :------------- | :----------- | :------------------------- |</span>
<span class="sd">        | `train_loader` | `torch.utils.data.DataLoader` | train set |</span>
<span class="sd">        | `dev_loader`   | `torch.utils.data.DataLoader` | dev set   |</span>
<span class="sd">        | `epochs`       | `int`        | number of epochs to train  |</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">epochs_slider</span><span class="o">.</span><span class="n">value</span>

    <span class="n">train_info</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">epoch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dynamic_params</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">epoch_idx</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_epoch</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dev_loader</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dev_loader</span> <span class="o">=</span> <span class="n">train_loader</span>
        <span class="n">acc</span><span class="p">,</span> <span class="n">conf_mat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">dev_loader</span><span class="p">)</span>
        <span class="n">train_info</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="n">acc</span><span class="p">,</span> <span class="s2">&quot;confusion_matrix&quot;</span><span class="p">:</span> <span class="n">conf_mat</span><span class="p">})</span>
    <span class="k">return</span> <span class="n">train_info</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="hover.core.neural.VectorNet.train_batch" class="doc doc-heading">
<code class="highlight language-python"><span class="n">train_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loaded_input</span><span class="p">,</span> <span class="n">loaded_output</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <details class="note" open="open">
<summary>Train the neural network for one batch.</summary>
<table>
<thead>
<tr>
<th align="left">Param</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><code>loaded_input</code></td>
<td align="left"><code>torch.Tensor</code></td>
<td align="left">input tensor</td>
</tr>
<tr>
<td align="left"><code>loaded_output</code></td>
<td align="left"><code>torch.Tensor</code></td>
<td align="left">output tensor</td>
</tr>
</tbody>
</table>
</details>

        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">train_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loaded_input</span><span class="p">,</span> <span class="n">loaded_output</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ???+ note &quot;Train the neural network for one batch.&quot;</span>

<span class="sd">        | Param           | Type           | Description           |</span>
<span class="sd">        | :-------------- | :------------- | :-------------------- |</span>
<span class="sd">        | `loaded_input`  | `torch.Tensor` | input tensor          |</span>
<span class="sd">        | `loaded_output` | `torch.Tensor` | output tensor         |</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">loaded_input</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">loaded_output</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

    <span class="c1"># compute logits</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">output_tensor</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">nn_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nn_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">log_info</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dynamic_params</span><span class="p">)</span>
        <span class="n">log_info</span><span class="p">[</span><span class="s2">&quot;performance&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;Loss </span><span class="si">{0:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_print</span><span class="p">(</span>
            <span class="s2">&quot;</span><span class="si">{0: &lt;80}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="s2">&quot;Train: Epoch </span><span class="si">{epoch}</span><span class="s2"> Batch </span><span class="si">{batch}</span><span class="s2"> </span><span class="si">{performance}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="o">**</span><span class="n">log_info</span>
                <span class="p">)</span>
            <span class="p">),</span>
            <span class="n">end</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="hover.core.neural.VectorNet.train_epoch" class="doc doc-heading">
<code class="highlight language-python"><span class="n">train_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <details class="note" open="open">
<summary>Train the neural network for one epoch.</summary>
<ul>
<li>Supports flexible args and kwargs for child classes that may implement self.train() and self.train_batch() differently.</li>
</ul>
<table>
<thead>
<tr>
<th align="left">Param</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><code>train_loader</code></td>
<td align="left"><code>torch.utils.data.DataLoader</code></td>
<td align="left">train set</td>
</tr>
<tr>
<td align="left"><code>*args</code></td>
<td align="left"></td>
<td align="left">arguments to forward to <code>train_batch</code></td>
</tr>
<tr>
<td align="left"><code>**kwargs</code></td>
<td align="left"></td>
<td align="left">kwargs to forward to <code>train_batch</code></td>
</tr>
</tbody>
</table>
</details>

        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ???+ note &quot;Train the neural network for one epoch.&quot;</span>

<span class="sd">        - Supports flexible args and kwargs for child classes that may implement self.train() and self.train_batch() differently.</span>

<span class="sd">        | Param          | Type         | Description                |</span>
<span class="sd">        | :------------- | :----------- | :------------------------- |</span>
<span class="sd">        | `train_loader` | `torch.utils.data.DataLoader` | train set |</span>
<span class="sd">        | `*args`        | | arguments to forward to `train_batch`   |</span>
<span class="sd">        | `**kwargs`     | | kwargs to forward to `train_batch`      |</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">adjust_optimizer_params</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">loaded_input</span><span class="p">,</span> <span class="n">loaded_output</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dynamic_params</span><span class="p">[</span><span class="s2">&quot;batch&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_idx</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_batch</span><span class="p">(</span><span class="n">loaded_input</span><span class="p">,</span> <span class="n">loaded_output</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="hover.core.neural.VectorNet.view" class="doc doc-heading">
<code class="highlight language-python"><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <details class="note" open="open">
<summary>Overall layout when plotted.</summary>
</details>

        <details class="quote">
          <summary>Source code in <code>hover/core/neural.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">view</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ???+ note &quot;Overall layout when plotted.&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layout_widgets</span><span class="p">()</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>







  </div>

    </div>

  </div>

<h2 data-role="module" id="hover.core.neural"></h2>
<h2 class="doc doc-heading" data-role="class" id="hover.core.neural.BaseVectorNet"></h2>
<h2 class="doc doc-heading" data-role="class" id="hover.core.neural.VectorNet"></h2>
<h3 class="doc doc-heading" data-role="class" id="hover.core.neural.VectorNet.DEFAULT_OPTIM_CLS"></h3>
<h4 class="doc doc-heading" data-role="method" id="hover.core.neural.VectorNet.DEFAULT_OPTIM_CLS.step"></h4>
<h3 class="doc doc-heading" data-role="method" id="hover.core.neural.VectorNet.__init__"></h3>
<h3 class="doc doc-heading" data-role="method" id="hover.core.neural.VectorNet.adjust_optimizer_params"></h3>
<h3 class="doc doc-heading" data-role="method" id="hover.core.neural.VectorNet.auto_adjust_setup"></h3>
<h3 class="doc doc-heading" data-role="method" id="hover.core.neural.VectorNet.evaluate"></h3>
<h3 class="doc doc-heading" data-role="method" id="hover.core.neural.VectorNet.from_module"></h3>
<h3 class="doc doc-heading" data-role="method" id="hover.core.neural.VectorNet.load"></h3>
<h3 class="doc doc-heading" data-role="method" id="hover.core.neural.VectorNet.manifold_trajectory"></h3>
<h3 class="doc doc-heading" data-role="method" id="hover.core.neural.VectorNet.predict_proba"></h3>
<h3 class="doc doc-heading" data-role="method" id="hover.core.neural.VectorNet.prepare_loader"></h3>
<h3 class="doc doc-heading" data-role="method" id="hover.core.neural.VectorNet.save"></h3>
<h3 class="doc doc-heading" data-role="method" id="hover.core.neural.VectorNet.setup_label_conversion"></h3>
<h3 class="doc doc-heading" data-role="method" id="hover.core.neural.VectorNet.setup_nn"></h3>
<h3 class="doc doc-heading" data-role="method" id="hover.core.neural.VectorNet.train"></h3>
<h3 class="doc doc-heading" data-role="method" id="hover.core.neural.VectorNet.train_batch"></h3>
<h3 class="doc doc-heading" data-role="method" id="hover.core.neural.VectorNet.train_epoch"></h3>
<h3 class="doc doc-heading" data-role="method" id="hover.core.neural.VectorNet.view"></h3>
</div>
</li>
</ul>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../core-explorer-specialization/" class="md-footer__link md-footer__link--prev" aria-label="Previous: .specialization" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              .specialization
            </div>
          </div>
        </a>
      
      
        
        <a href="../core-representation/" class="md-footer__link md-footer__link--next" aria-label="Next: hover.core.representation" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              hover.core.representation
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.expand", "navigation.tabs", "search.suggest", "toc.integrate"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../../assets/javascripts/workers/search.22074ed6.min.js"}</script>
    
    
      <script src="../../../assets/javascripts/bundle.960e086b.min.js"></script>
      
    
  </body>
</html>